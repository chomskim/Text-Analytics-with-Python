{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHAPTER 7 Semantic and Sentiment Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring WordNet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Synsets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Synsets: 5\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "term = 'fruit'\n",
    "synsets = wn.synsets(term)\n",
    "\n",
    "print 'Total Synsets:', len(synsets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset: Synset('fruit.n.01')\n",
      "Part of speech: noun.plant\n",
      "Definition: the ripened reproductive body of a seed plant\n",
      "Lemmas: [u'fruit']\n",
      "Examples: []\n",
      "\n",
      "Synset: Synset('yield.n.03')\n",
      "Part of speech: noun.artifact\n",
      "Definition: an amount of a product\n",
      "Lemmas: [u'yield', u'fruit']\n",
      "Examples: []\n",
      "\n",
      "Synset: Synset('fruit.n.03')\n",
      "Part of speech: noun.event\n",
      "Definition: the consequence of some effort or action\n",
      "Lemmas: [u'fruit']\n",
      "Examples: [u'he lived long enough to see the fruit of his policies']\n",
      "\n",
      "Synset: Synset('fruit.v.01')\n",
      "Part of speech: verb.creation\n",
      "Definition: cause to bear fruit\n",
      "Lemmas: [u'fruit']\n",
      "Examples: []\n",
      "\n",
      "Synset: Synset('fruit.v.02')\n",
      "Part of speech: verb.creation\n",
      "Definition: bear fruit\n",
      "Lemmas: [u'fruit']\n",
      "Examples: [u'the trees fruited early this year']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# synsets for fruit\n",
    "for synset in synsets:\n",
    "    print 'Synset:', synset\n",
    "    print 'Part of speech:', synset.lexname()\n",
    "    print 'Definition:', synset.definition()\n",
    "    print 'Lemmas:', synset.lemma_names()\n",
    "    print 'Examples:', synset.examples()\n",
    "    print\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing Lexical Semantic Relations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('walk.v.01') -- entails --> [Synset('step.v.01')]\n",
      "Synset('eat.v.01') -- entails --> [Synset('chew.v.01'), Synset('swallow.v.01')]\n",
      "Synset('digest.v.01') -- entails --> [Synset('consume.v.02')]\n"
     ]
    }
   ],
   "source": [
    "# entailments\n",
    "for action in ['walk', 'eat', 'digest']:\n",
    "    action_syn = wn.synsets(action, pos='v')[0]\n",
    "    print action_syn, '-- entails -->', action_syn.entailments()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bank.n.01 - sloping land (especially the slope beside a body of water)\n",
      "depository_financial_institution.n.01 - a financial institution that accepts deposits and channels the money into lending activities\n",
      "bank.n.03 - a long ridge or pile\n",
      "bank.n.04 - an arrangement of similar objects in a row or in tiers\n",
      "bank.n.05 - a supply or stock held in reserve for future use (especially in emergencies)\n",
      "bank.n.06 - the funds held by a gambling house or the dealer in some gambling games\n",
      "bank.n.07 - a slope in the turn of a road or track; the outside is higher than the inside in order to reduce the effects of centrifugal force\n",
      "savings_bank.n.02 - a container (usually with a slot in the top) for keeping money at home\n",
      "bank.n.09 - a building in which the business of banking transacted\n",
      "bank.n.10 - a flight maneuver; aircraft tips laterally about its longitudinal axis (especially in turning)\n",
      "bank.v.01 - tip laterally\n",
      "bank.v.02 - enclose with a bank\n",
      "bank.v.03 - do business with a bank or keep an account at a bank\n",
      "bank.v.04 - act as the banker in a game or in gambling\n",
      "bank.v.05 - be in the banking business\n",
      "deposit.v.02 - put into a bank account\n",
      "bank.v.07 - cover with ashes so to control the rate of burning\n",
      "trust.v.01 - have confidence or faith in\n"
     ]
    }
   ],
   "source": [
    "# homonyms\\homographs  \n",
    "for synset in wn.synsets('bank'):\n",
    "    print synset.name(),'-',synset.definition()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synonym: large.a.01\n",
      "Definition: above average in size or number or quantity or magnitude or extent\n",
      "Antonym: small.a.01\n",
      "Definition: limited or below average in number or quantity or magnitude or extent\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# synonyms and antonyms\n",
    "term = 'large'\n",
    "synsets = wn.synsets(term)\n",
    "adj_large = synsets[1]\n",
    "adj_large = adj_large.lemmas()[0]\n",
    "adj_large_synonym = adj_large.synset()\n",
    "adj_large_antonym = adj_large.antonyms()[0].synset()\n",
    "\n",
    "print 'Synonym:', adj_large_synonym.name()\n",
    "print 'Definition:', adj_large_synonym.definition()\n",
    "print 'Antonym:', adj_large_antonym.name()\n",
    "print 'Definition:', adj_large_antonym.definition()\n",
    "print\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synonym: rich_people.n.01\n",
      "Definition: people who have possessions and wealth (considered as a group)\n",
      "Antonym: poor_people.n.01\n",
      "Definition: people without possessions or wealth (considered as a group)\n",
      "\n",
      "Synonym: rich.a.01\n",
      "Definition: possessing material wealth\n",
      "Antonym: poor.a.02\n",
      "Definition: having little money or few possessions\n",
      "\n",
      "Synonym: rich.a.02\n",
      "Definition: having an abundant supply of desirable qualities or substances (especially natural resources)\n",
      "Antonym: poor.a.04\n",
      "Definition: lacking in specific resources, qualities or substances\n",
      "\n"
     ]
    }
   ],
   "source": [
    "term = 'rich'\n",
    "synsets = wn.synsets(term)[:3]\n",
    "\n",
    "for synset in synsets:\n",
    "    rich = synset.lemmas()[0]\n",
    "    rich_synonym = rich.synset()\n",
    "    rich_antonym = rich.antonyms()[0].synset()\n",
    "    print 'Synonym:', rich_synonym.name()\n",
    "    print 'Definition:', rich_synonym.definition()\n",
    "    print 'Antonym:', rich_antonym.name()\n",
    "    print 'Definition:', rich_antonym.definition()\n",
    "    print\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tree.n.01\n",
      "Definition: a tall perennial woody plant having a main trunk and branches forming a distinct elevated crown; includes both gymnosperms and angiosperms\n"
     ]
    }
   ],
   "source": [
    "# hyponyms and hypernyms\n",
    "term = 'tree'\n",
    "synsets = wn.synsets(term)\n",
    "tree = synsets[0]\n",
    "\n",
    "print 'Name:', tree.name()\n",
    "print 'Definition:', tree.definition()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Hyponyms: 180\n",
      "Sample Hyponyms\n",
      "aalii.n.01 - a small Hawaiian tree with hard dark wood\n",
      "\n",
      "acacia.n.01 - any of various spiny trees or shrubs of the genus Acacia\n",
      "\n",
      "african_walnut.n.01 - tropical African timber tree with wood that resembles mahogany\n",
      "\n",
      "albizzia.n.01 - any of numerous trees of the genus Albizia\n",
      "\n",
      "alder.n.02 - north temperate shrubs or trees having toothed leaves and conelike fruit; bark is used in tanning and dyeing and the wood is rot-resistant\n",
      "\n",
      "angelim.n.01 - any of several tropical American trees of the genus Andira\n",
      "\n",
      "angiospermous_tree.n.01 - any tree having seeds and ovules contained in the ovary\n",
      "\n",
      "anise_tree.n.01 - any of several evergreen shrubs and small trees of the genus Illicium\n",
      "\n",
      "arbor.n.01 - tree (as opposed to shrub)\n",
      "\n",
      "aroeira_blanca.n.01 - small resinous tree or shrub of Brazil\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hyponyms = tree.hyponyms()\n",
    "print 'Total Hyponyms:', len(hyponyms)\n",
    "print 'Sample Hyponyms'\n",
    "for hyponym in hyponyms[:10]:\n",
    "    print hyponym.name(), '-', hyponym.definition()\n",
    "    print\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('woody_plant.n.01')]\n"
     ]
    }
   ],
   "source": [
    "hypernyms = tree.hypernyms()\n",
    "print hypernyms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Hypernym paths: 1\n",
      "Hypernym Hierarchy\n",
      "entity.n.01 -> physical_entity.n.01 -> object.n.01 -> whole.n.02 -> living_thing.n.01 -> organism.n.01 -> plant.n.02 -> vascular_plant.n.01 -> woody_plant.n.01 -> tree.n.01\n"
     ]
    }
   ],
   "source": [
    "hypernym_paths = tree.hypernym_paths()\n",
    "print 'Total Hypernym paths:', len(hypernym_paths)\n",
    "\n",
    "print 'Hypernym Hierarchy'\n",
    "print ' -> '.join(synset.name() for synset in hypernym_paths[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Member Holonyms: 1\n",
      "Member Holonyms for [tree]:-\n",
      "forest.n.01 - the trees and other plants in a large densely wooded area\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# holonyms and meronyms\n",
    "\n",
    "# member holonyms\n",
    "member_holonyms = tree.member_holonyms()    \n",
    "print 'Total Member Holonyms:', len(member_holonyms)\n",
    "print 'Member Holonyms for [tree]:-'\n",
    "for holonym in member_holonyms:\n",
    "    print holonym.name(), '-', holonym.definition()\n",
    "    print\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Part Meronyms: 5\n",
      "Part Meronyms for [tree]:-\n",
      "burl.n.02 - a large rounded outgrowth on the trunk or branch of a tree\n",
      "\n",
      "crown.n.07 - the upper branches and leaves of a tree or other plant\n",
      "\n",
      "limb.n.02 - any of the main branches arising from the trunk or a bough of a tree\n",
      "\n",
      "stump.n.01 - the base part of a tree that remains standing after the tree has been felled\n",
      "\n",
      "trunk.n.01 - the main stem of a tree; usually covered with bark; the bole is usually the part that is commercially useful for lumber\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# part meronyms\n",
    "part_meronyms = tree.part_meronyms()\n",
    "print 'Total Part Meronyms:', len(part_meronyms)\n",
    "print 'Part Meronyms for [tree]:-'\n",
    "for meronym in part_meronyms:\n",
    "    print meronym.name(), '-', meronym.definition()\n",
    "    print\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Substance Meronyms: 2\n",
      "Substance Meronyms for [tree]:-\n",
      "heartwood.n.01 - the older inactive central wood of a tree or woody plant; usually darker and denser than the surrounding sapwood\n",
      "\n",
      "sapwood.n.01 - newly formed outer wood lying between the cambium and the heartwood of a tree or woody plant; usually light colored; active in water conduction\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# substance meronyms\n",
    "substance_meronyms = tree.substance_meronyms()    \n",
    "print 'Total Substance Meronyms:', len(substance_meronyms)\n",
    "print 'Substance Meronyms for [tree]:-'\n",
    "for meronym in substance_meronyms:\n",
    "    print meronym.name(), '-', meronym.definition()\n",
    "    print\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic Relationships and Similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree - a tall perennial woody plant having a main trunk and branches forming a distinct elevated crown; includes both gymnosperms and angiosperms\n",
      "\n",
      "lion - large gregarious predatory feline of Africa and India having a tawny coat with a shaggy mane in the male\n",
      "\n",
      "tiger - large feline of forests in most of Asia having a tawny coat with black stripes; endangered\n",
      "\n",
      "cat - feline mammal usually having thick soft fur and no ability to roar: domestic cats; wildcats\n",
      "\n",
      "dog - a member of the genus Canis (probably descended from the common wolf) that has been domesticated by man since prehistoric times; occurs in many breeds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# semantic relationships and similarities\n",
    "tree = wn.synset('tree.n.01')\n",
    "lion = wn.synset('lion.n.01')\n",
    "tiger = wn.synset('tiger.n.02')\n",
    "cat = wn.synset('cat.n.01')\n",
    "dog = wn.synset('dog.n.01')\n",
    "\n",
    "entities = [tree, lion, tiger, cat, dog]\n",
    "entity_names = [entity.name().split('.')[0] for entity in entities]\n",
    "entity_definitions = [entity.definition() for entity in entities]\n",
    "\n",
    "for entity, definition in zip(entity_names, entity_definitions):\n",
    "    print entity, '-', definition\n",
    "    print\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           tree       lion      tiger        cat        dog\n",
      "tree       tree   organism   organism   organism   organism\n",
      "lion   organism       lion    big_cat     feline  carnivore\n",
      "tiger  organism    big_cat      tiger     feline  carnivore\n",
      "cat    organism     feline     feline        cat  carnivore\n",
      "dog    organism  carnivore  carnivore  carnivore        dog\n"
     ]
    }
   ],
   "source": [
    "common_hypernyms = []\n",
    "for entity in entities:\n",
    "    # get pairwise lowest common hypernyms\n",
    "    common_hypernyms.append([entity.lowest_common_hypernyms(compared_entity)[0]\n",
    "                                            .name().split('.')[0]\n",
    "                             for compared_entity in entities])\n",
    "# build pairwise lower common hypernym matrix\n",
    "common_hypernym_frame = pd.DataFrame(common_hypernyms,\n",
    "                                     index=entity_names, \n",
    "                                     columns=entity_names)\n",
    "                                     \n",
    "print common_hypernym_frame    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       tree  lion  tiger   cat   dog\n",
      "tree   1.00  0.07   0.07  0.08  0.13\n",
      "lion   0.07  1.00   0.33  0.25  0.17\n",
      "tiger  0.07  0.33   1.00  0.25  0.17\n",
      "cat    0.08  0.25   0.25  1.00  0.20\n",
      "dog    0.13  0.17   0.17  0.20  1.00\n"
     ]
    }
   ],
   "source": [
    "similarities = []\n",
    "for entity in entities:\n",
    "    # get pairwise similarities\n",
    "    similarities.append([round(entity.path_similarity(compared_entity), 2)\n",
    "                         for compared_entity in entities])        \n",
    "# build pairwise similarity matrix                             \n",
    "similarity_frame = pd.DataFrame(similarities,\n",
    "                                index=entity_names, \n",
    "                                columns=entity_names)\n",
    "                                     \n",
    "print similarity_frame \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Sense Disambiguation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: The fruits on that plant have ripened\n",
      "Word synset: Synset('fruit.n.01')\n",
      "Corresponding defition: the ripened reproductive body of a seed plant\n",
      "\n",
      "Sentence: He finally reaped the fruit of his hard work as he won the race\n",
      "Word synset: Synset('fruit.n.03')\n",
      "Corresponding defition: the consequence of some effort or action\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.wsd import lesk\n",
    "from nltk import word_tokenize\n",
    "\n",
    "samples = [('The fruits on that plant have ripened', 'n'),\n",
    "           ('He finally reaped the fruit of his hard work as he won the race', 'n')]\n",
    "\n",
    "word = 'fruit'\n",
    "for sentence, pos_tag in samples:\n",
    "    word_syn = lesk(word_tokenize(sentence.lower()), word, pos_tag)\n",
    "    print 'Sentence:', sentence\n",
    "    print 'Word synset:', word_syn\n",
    "    print 'Corresponding defition:', word_syn.definition()\n",
    "    print\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Lead is a very soft, malleable metal\n",
      "Word synset: Synset('lead.n.02')\n",
      "Corresponding defition: a soft heavy toxic malleable metallic element; bluish white when freshly cut but tarnishes readily to dull grey\n",
      "\n",
      "Sentence: John is the actor who plays the lead in that movie\n",
      "Word synset: Synset('star.n.04')\n",
      "Corresponding defition: an actor who plays a principal role\n",
      "\n",
      "Sentence: This road leads to nowhere\n",
      "Word synset: Synset('run.v.23')\n",
      "Corresponding defition: cause something to pass or lead somewhere\n",
      "\n"
     ]
    }
   ],
   "source": [
    "samples = [('Lead is a very soft, malleable metal', 'n'),\n",
    "           ('John is the actor who plays the lead in that movie', 'n'),\n",
    "           ('This road leads to nowhere', 'v')]\n",
    "word = 'lead'\n",
    "\n",
    "for sentence, pos_tag in samples:\n",
    "    word_syn = lesk(word_tokenize(sentence.lower()), word, pos_tag)\n",
    "    print 'Sentence:', sentence\n",
    "    print 'Word synset:', word_syn\n",
    "    print 'Corresponding defition:', word_syn.definition()\n",
    "    print\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Bayern Munich, or FC Bayern, is a German sports club based in Munich, \n",
    "Bavaria, Germany. It is best known for its professional football team, \n",
    "which plays in the Bundesliga, the top tier of the German football \n",
    "league system, and is the most successful club in German football \n",
    "history, having won a record 26 national titles and 18 national cups. \n",
    "FC Bayern was founded in 1900 by eleven football players led by Franz John. \n",
    "Although Bayern won its first national championship in 1932, the club \n",
    "was not selected for the Bundesliga at its inception in 1963. The club \n",
    "had its period of greatest success in the middle of the 1970s when, \n",
    "under the captaincy of Franz Beckenbauer, it won the European Cup three \n",
    "times in a row (1974-76). Overall, Bayern has reached ten UEFA Champions \n",
    "League finals, most recently winning their fifth title in 2013 as part \n",
    "of a continental treble. \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from normalization import parse_document\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = parse_document(text)\n",
    "tokenized_sentences = [nltk.word_tokenize(sentence) for sentence in sentences]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Entity Name   Entity Type\n",
      "0              Bayern        PERSON\n",
      "1          Franz John        PERSON\n",
      "2   Franz Beckenbauer        PERSON\n",
      "3              Munich  ORGANIZATION\n",
      "4            European  ORGANIZATION\n",
      "5          Bundesliga  ORGANIZATION\n",
      "6              German           GPE\n",
      "7             Bavaria           GPE\n",
      "8             Germany           GPE\n",
      "9           FC Bayern  ORGANIZATION\n",
      "10               UEFA  ORGANIZATION\n",
      "11             Munich           GPE\n",
      "12             Bayern           GPE\n",
      "13            Overall           GPE\n"
     ]
    }
   ],
   "source": [
    "# nltk NER\n",
    "tagged_sentences = [nltk.pos_tag(sentence) for sentence in tokenized_sentences]\n",
    "ne_chunked_sents = [nltk.ne_chunk(tagged) for tagged in tagged_sentences]\n",
    "named_entities = []\n",
    "for ne_tagged_sentence in ne_chunked_sents:\n",
    "    for tagged_tree in ne_tagged_sentence:\n",
    "        if hasattr(tagged_tree, 'label'):\n",
    "                entity_name = ' '.join(c[0] for c in tagged_tree.leaves())\n",
    "                entity_type = tagged_tree.label()\n",
    "                named_entities.append((entity_name, entity_type))\n",
    "                \n",
    "named_entities = list(set(named_entities))\n",
    "entity_frame = pd.DataFrame(named_entities, \n",
    "                            columns=['Entity Name', 'Entity Type'])\n",
    "print entity_frame    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set java path\n",
    "import os\n",
    "java_path = r'/usr/bin/java'\n",
    "os.environ['JAVAHOME'] = java_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tag import StanfordNERTagger\n",
    "sn = StanfordNERTagger('/pub/nltk-parser/stanford-ner/classifiers/english.all.3class.distsim.crf.ser.gz',\n",
    "                       path_to_jar='/pub/nltk-parser/stanford-ner/stanford-ner.jar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ne_annotated_sentences = [sn.tag(sent) for sent in tokenized_sentences]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Entity Name   Entity Type\n",
      "0         Franz John        PERSON\n",
      "1  Franz Beckenbauer        PERSON\n",
      "2            Germany      LOCATION\n",
      "3             Bayern  ORGANIZATION\n",
      "4            Bavaria      LOCATION\n",
      "5             Munich      LOCATION\n",
      "6          FC Bayern  ORGANIZATION\n",
      "7      Bayern Munich  ORGANIZATION\n"
     ]
    }
   ],
   "source": [
    "named_entities = []\n",
    "for sentence in ne_annotated_sentences:\n",
    "    temp_entity_name = ''\n",
    "    temp_named_entity = None\n",
    "    for term, tag in sentence:\n",
    "        if tag != 'O':\n",
    "            temp_entity_name = ' '.join([temp_entity_name, term]).strip()\n",
    "            temp_named_entity = (temp_entity_name, tag)\n",
    "        else:\n",
    "            if temp_named_entity:\n",
    "                named_entities.append(temp_named_entity)\n",
    "                temp_entity_name = ''\n",
    "                temp_named_entity = None\n",
    "\n",
    "named_entities = list(set(named_entities))\n",
    "entity_frame = pd.DataFrame(named_entities, \n",
    "                            columns=['Entity Name', 'Entity Type'])\n",
    "print entity_frame                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Semantic Representations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: He is hungry\n",
      "Q: He will eat a sandwich\n",
      "\n",
      "Expression Outcomes:-\n",
      "       P      Q (P & Q) (P | Q) (P -> Q) (P <-> Q)\n",
      "0  False  False   False   False     True      True\n",
      "1  False   True   False    True     True     False\n",
      "2   True  False   False    True    False     False\n",
      "3   True   True    True    True     True      True\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import os\n",
    "# assign symbols and propositions\n",
    "symbol_P = 'P'\n",
    "symbol_Q = 'Q'\n",
    "proposition_P = 'He is hungry'\n",
    "propositon_Q = 'He will eat a sandwich'\n",
    "# assign various truth values to the propositions\n",
    "p_statuses = [False, False, True, True]\n",
    "q_statuses = [False, True, False, True]\n",
    "# assign the various expressions combining the logical operators\n",
    "conjunction = '(P & Q)'\n",
    "disjunction = '(P | Q)'\n",
    "implication = '(P -> Q)'\n",
    "equivalence = '(P <-> Q)'\n",
    "expressions = [conjunction, disjunction, implication, equivalence]\n",
    "\n",
    "\n",
    "results = []\n",
    "for status_p, status_q in zip(p_statuses, q_statuses):\n",
    "    dom = set([])\n",
    "    val = nltk.Valuation([(symbol_P, status_p), \n",
    "                          (symbol_Q, status_q)])\n",
    "    assignments = nltk.Assignment(dom)\n",
    "    model = nltk.Model(dom, val)\n",
    "    row = [status_p, status_q]\n",
    "    for expression in expressions:\n",
    "        result = model.evaluate(expression, assignments)\n",
    "        row.append(result)\n",
    "    results.append(row)\n",
    "    \n",
    "columns = [symbol_P, symbol_Q, conjunction, \n",
    "           disjunction, implication, equivalence]           \n",
    "result_frame = pd.DataFrame(results, columns=columns)\n",
    "\n",
    "print 'P:', proposition_P\n",
    "print 'Q:', propositon_Q\n",
    "print\n",
    "print 'Expression Outcomes:-'\n",
    "print result_frame   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first order logic\n",
    "\n",
    "read_expr = nltk.sem.Expression.fromstring\n",
    "os.environ['PROVER9'] = r'/usr/local/bin/prover9'\n",
    "prover = nltk.Prover9()\n",
    "#prover = nltk.ResolutionProver()   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Found prover9: /usr/local/bin/prover9/bin/prover9]\n",
      "Calling: /usr/local/bin/prover9/bin/prover9\n",
      "Args: []\n",
      "Input:\n",
      " assign(max_seconds, 60).\n",
      "\n",
      "clear(auto_denials).\n",
      "formulas(assumptions).\n",
      "    jumps_over(fox,dog).\n",
      "    all x all y (jumps_over(x,y) -> -(jumps_over(y,x))).\n",
      "end_of_list.\n",
      "\n",
      "formulas(goals).\n",
      "    jumps_over(dog,fox).\n",
      "end_of_list.\n",
      "\n",
      " \n",
      "\n",
      "Return code: 2\n",
      "stdout:\n",
      " ============================== Prover9 ===============================\n",
      "Prover9 (64) version 2009-11A, November 2009.\n",
      "Process 23030 was started by cskim on ubuva,\n",
      "Mon Jun 19 23:24:40 2017\n",
      "The command was \"/usr/local/bin/prover9/bin/prover9\".\n",
      "============================== end of head ===========================\n",
      "\n",
      "============================== INPUT =================================\n",
      "assign(max_seconds,60).\n",
      "clear(auto_denials).\n",
      "\n",
      "formulas(assumptions).\n",
      "jumps_over(fox,dog).\n",
      "(all x all y (jumps_over(x,y) -> -jumps_over(y,x))).\n",
      "end_of_list.\n",
      "\n",
      "formulas(goals).\n",
      "jumps_over(dog,fox).\n",
      "end_of_list.\n",
      "\n",
      "============================== end of input ==========================\n",
      "\n",
      "============================== PROCESS NON-CLAUSAL FORMULAS ==========\n",
      "\n",
      "% Formulas that are not ordinary clauses:\n",
      "1 (all x all y (jumps_over(x,y) -> -jumps_over(y,x))) # label(non_clause).  [assumption].\n",
      "2 jumps_over(dog,fox) # label(non_clause) # label(goal).  [goal].\n",
      "\n",
      "============================== end of process non-clausal formulas ===\n",
      "\n",
      "============================== PROCESS INITIAL CLAUSES ===============\n",
      "\n",
      "% Clauses before input processing:\n",
      "\n",
      "formulas(usable).\n",
      "end_of_list.\n",
      "\n",
      "formulas(sos).\n",
      "jumps_over(fox,dog).  [assumption].\n",
      "-jumps_over(x,y) | -jumps_over(y,x).  [clausify(1)].\n",
      "-jumps_over(dog,fox).  [deny(2)].\n",
      "end_of_list.\n",
      "\n",
      "formulas(demodulators).\n",
      "end_of_list.\n",
      "\n",
      "============================== PREDICATE ELIMINATION =================\n",
      "\n",
      "No predicates eliminated.\n",
      "\n",
      "============================== end predicate elimination =============\n",
      "\n",
      "Term ordering decisions:\n",
      "Predicate symbol precedence:  predicate_order([ jumps_over ]).\n",
      "Function symbol precedence:  function_order([ dog, fox ]).\n",
      "After inverse_order:  (no changes).\n",
      "Unfolding symbols: (none).\n",
      "\n",
      "Auto_inference settings:\n",
      "  % set(neg_binary_resolution).  % (HNE depth_diff=0)\n",
      "  % clear(ordered_res).  % (HNE depth_diff=0)\n",
      "  % set(ur_resolution).  % (HNE depth_diff=0)\n",
      "    % set(ur_resolution) -> set(pos_ur_resolution).\n",
      "    % set(ur_resolution) -> set(neg_ur_resolution).\n",
      "\n",
      "Auto_process settings:\n",
      "  % set(unit_deletion).  % (Horn set with negative nonunits)\n",
      "\n",
      "kept:      3 jumps_over(fox,dog).  [assumption].\n",
      "kept:      4 -jumps_over(x,y) | -jumps_over(y,x).  [clausify(1)].\n",
      "kept:      5 -jumps_over(dog,fox).  [deny(2)].\n",
      "\n",
      "============================== end of process initial clauses ========\n",
      "\n",
      "============================== CLAUSES FOR SEARCH ====================\n",
      "\n",
      "% Clauses after input processing:\n",
      "\n",
      "formulas(usable).\n",
      "end_of_list.\n",
      "\n",
      "formulas(sos).\n",
      "3 jumps_over(fox,dog).  [assumption].\n",
      "4 -jumps_over(x,y) | -jumps_over(y,x).  [clausify(1)].\n",
      "5 -jumps_over(dog,fox).  [deny(2)].\n",
      "end_of_list.\n",
      "\n",
      "formulas(demodulators).\n",
      "end_of_list.\n",
      "\n",
      "============================== end of clauses for search =============\n",
      "\n",
      "============================== SEARCH ================================\n",
      "\n",
      "% Starting search at 0.00 seconds.\n",
      "\n",
      "given #1 (I,wt=3): 3 jumps_over(fox,dog).  [assumption].\n",
      "\n",
      "given #2 (I,wt=6): 4 -jumps_over(x,y) | -jumps_over(y,x).  [clausify(1)].\n",
      "\n",
      "given #3 (I,wt=3): 5 -jumps_over(dog,fox).  [deny(2)].\n",
      "\n",
      "============================== STATISTICS ============================\n",
      "\n",
      "Given=3. Generated=7. Kept=3. proofs=0.\n",
      "Usable=3. Sos=0. Demods=0. Limbo=0, Disabled=3. Hints=0.\n",
      "Kept_by_rule=0, Deleted_by_rule=0.\n",
      "Forward_subsumed=4. Back_subsumed=0.\n",
      "Sos_limit_deleted=0. Sos_displaced=0. Sos_removed=0.\n",
      "New_demodulators=0 (0 lex), Back_demodulated=0. Back_unit_deleted=0.\n",
      "Demod_attempts=0. Demod_rewrites=0.\n",
      "Res_instance_prunes=0. Para_instance_prunes=0. Basic_paramod_prunes=0.\n",
      "Nonunit_fsub_feature_tests=0. Nonunit_bsub_feature_tests=1.\n",
      "Megabytes=0.03.\n",
      "User_CPU=0.00, System_CPU=0.00, Wall_clock=0.\n",
      "\n",
      "============================== end of statistics =====================\n",
      "\n",
      "============================== end of search =========================\n",
      "\n",
      "SEARCH FAILED\n",
      "\n",
      "SEARCH FAILED\n",
      "\n",
      "Exiting with failure.\n",
      "\n",
      "------ process 23030 exit (sos_empty) ------\n",
      "\u0007\n",
      "Process 23030 exit (sos_empty) Mon Jun 19 23:24:40 2017\n",
      " \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the rule expression\n",
    "rule = read_expr('all x. all y. (jumps_over(x, y) -> -jumps_over(y, x))')\n",
    "# set the event occured\n",
    "event = read_expr('jumps_over(fox, dog)')\n",
    "# set the outcome we want to evaluate -- the goal\n",
    "test_outcome = read_expr('jumps_over(dog, fox)')\n",
    "\n",
    "# get the result\n",
    "prover.prove(goal=test_outcome, \n",
    "             assumptions=[event, rule],\n",
    "             verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling: /usr/local/bin/prover9/bin/prover9\n",
      "Args: []\n",
      "Input:\n",
      " assign(max_seconds, 60).\n",
      "\n",
      "clear(auto_denials).\n",
      "formulas(assumptions).\n",
      "    -(studies(John,exam)).\n",
      "    all x (studies(x,exam) -> pass(x,exam)).\n",
      "end_of_list.\n",
      "\n",
      "formulas(goals).\n",
      "    pass(John,exam).\n",
      "end_of_list.\n",
      "\n",
      " \n",
      "\n",
      "Return code: 2\n",
      "stdout:\n",
      " ============================== Prover9 ===============================\n",
      "Prover9 (64) version 2009-11A, November 2009.\n",
      "Process 23031 was started by cskim on ubuva,\n",
      "Mon Jun 19 23:24:40 2017\n",
      "The command was \"/usr/local/bin/prover9/bin/prover9\".\n",
      "============================== end of head ===========================\n",
      "\n",
      "============================== INPUT =================================\n",
      "assign(max_seconds,60).\n",
      "clear(auto_denials).\n",
      "\n",
      "formulas(assumptions).\n",
      "-studies(John,exam).\n",
      "(all x (studies(x,exam) -> pass(x,exam))).\n",
      "end_of_list.\n",
      "\n",
      "formulas(goals).\n",
      "pass(John,exam).\n",
      "end_of_list.\n",
      "\n",
      "============================== end of input ==========================\n",
      "\n",
      "============================== PROCESS NON-CLAUSAL FORMULAS ==========\n",
      "\n",
      "% Formulas that are not ordinary clauses:\n",
      "1 (all x (studies(x,exam) -> pass(x,exam))) # label(non_clause).  [assumption].\n",
      "2 pass(John,exam) # label(non_clause) # label(goal).  [goal].\n",
      "\n",
      "============================== end of process non-clausal formulas ===\n",
      "\n",
      "============================== PROCESS INITIAL CLAUSES ===============\n",
      "\n",
      "% Clauses before input processing:\n",
      "\n",
      "formulas(usable).\n",
      "end_of_list.\n",
      "\n",
      "formulas(sos).\n",
      "-studies(John,exam).  [assumption].\n",
      "-studies(x,exam) | pass(x,exam).  [clausify(1)].\n",
      "-pass(John,exam).  [deny(2)].\n",
      "end_of_list.\n",
      "\n",
      "formulas(demodulators).\n",
      "end_of_list.\n",
      "\n",
      "============================== PREDICATE ELIMINATION =================\n",
      "\n",
      "Eliminating studies/2\n",
      "\n",
      "Eliminating pass/2\n",
      "\n",
      "============================== end predicate elimination =============\n",
      "\n",
      "Term ordering decisions:\n",
      "Predicate symbol precedence:  predicate_order([ ]).\n",
      "Function symbol precedence:  function_order([ ]).\n",
      "After inverse_order:  (no changes).\n",
      "Unfolding symbols: (none).\n",
      "\n",
      "Auto_inference settings:\n",
      "  % set(neg_binary_resolution).  % (HNE depth_diff=0)\n",
      "  % clear(ordered_res).  % (HNE depth_diff=0)\n",
      "  % set(ur_resolution).  % (HNE depth_diff=0)\n",
      "    % set(ur_resolution) -> set(pos_ur_resolution).\n",
      "    % set(ur_resolution) -> set(neg_ur_resolution).\n",
      "\n",
      "Auto_process settings:  (no changes).\n",
      "\n",
      "\n",
      "============================== end of process initial clauses ========\n",
      "\n",
      "============================== CLAUSES FOR SEARCH ====================\n",
      "\n",
      "% Clauses after input processing:\n",
      "\n",
      "formulas(usable).\n",
      "end_of_list.\n",
      "\n",
      "formulas(sos).\n",
      "end_of_list.\n",
      "\n",
      "formulas(demodulators).\n",
      "end_of_list.\n",
      "\n",
      "============================== end of clauses for search =============\n",
      "\n",
      "============================== SEARCH ================================\n",
      "\n",
      "% Starting search at 0.00 seconds.\n",
      "\n",
      "============================== STATISTICS ============================\n",
      "\n",
      "Given=0. Generated=0. Kept=0. proofs=0.\n",
      "Usable=0. Sos=0. Demods=0. Limbo=0, Disabled=3. Hints=0.\n",
      "Kept_by_rule=0, Deleted_by_rule=0.\n",
      "Forward_subsumed=0. Back_subsumed=0.\n",
      "Sos_limit_deleted=0. Sos_displaced=0. Sos_removed=0.\n",
      "New_demodulators=0 (0 lex), Back_demodulated=0. Back_unit_deleted=0.\n",
      "Demod_attempts=0. Demod_rewrites=0.\n",
      "Res_instance_prunes=0. Para_instance_prunes=0. Basic_paramod_prunes=0.\n",
      "Nonunit_fsub_feature_tests=0. Nonunit_bsub_feature_tests=0.\n",
      "Megabytes=0.02.\n",
      "User_CPU=0.00, System_CPU=0.00, Wall_clock=0.\n",
      "\n",
      "============================== end of statistics =====================\n",
      "\n",
      "============================== end of search =========================\n",
      "\n",
      "SEARCH FAILED\n",
      "\n",
      "SEARCH FAILED\n",
      "\n",
      "Exiting with failure.\n",
      "\n",
      "------ process 23031 exit (sos_empty) ------\n",
      "\u0007\n",
      "Process 23031 exit (sos_empty) Mon Jun 19 23:24:40 2017\n",
      " \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the rule expression                          \n",
    "rule = read_expr('all x. (studies(x, exam) -> pass(x, exam))') \n",
    "# set the events and outcomes we want to determine\n",
    "event1 = read_expr('-studies(John, exam)')  \n",
    "test_outcome1 = read_expr('pass(John, exam)') \n",
    "event2 = read_expr('studies(Pierre, exam)')  \n",
    "test_outcome2 = read_expr('pass(Pierre, exam)') \n",
    "\n",
    "prover.prove(goal=test_outcome1, \n",
    "             assumptions=[event1, rule],\n",
    "             verbose=True)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling: /usr/local/bin/prover9/bin/prover9\n",
      "Args: []\n",
      "Input:\n",
      " assign(max_seconds, 60).\n",
      "\n",
      "clear(auto_denials).\n",
      "formulas(assumptions).\n",
      "    studies(Pierre,exam).\n",
      "    all x (studies(x,exam) -> pass(x,exam)).\n",
      "end_of_list.\n",
      "\n",
      "formulas(goals).\n",
      "    pass(Pierre,exam).\n",
      "end_of_list.\n",
      "\n",
      " \n",
      "\n",
      "Return code: 0\n",
      "stdout:\n",
      " ============================== Prover9 ===============================\n",
      "Prover9 (64) version 2009-11A, November 2009.\n",
      "Process 23032 was started by cskim on ubuva,\n",
      "Mon Jun 19 23:24:40 2017\n",
      "The command was \"/usr/local/bin/prover9/bin/prover9\".\n",
      "============================== end of head ===========================\n",
      "\n",
      "============================== INPUT =================================\n",
      "assign(max_seconds,60).\n",
      "clear(auto_denials).\n",
      "\n",
      "formulas(assumptions).\n",
      "studies(Pierre,exam).\n",
      "(all x (studies(x,exam) -> pass(x,exam))).\n",
      "end_of_list.\n",
      "\n",
      "formulas(goals).\n",
      "pass(Pierre,exam).\n",
      "end_of_list.\n",
      "\n",
      "============================== end of input ==========================\n",
      "\n",
      "============================== PROCESS NON-CLAUSAL FORMULAS ==========\n",
      "\n",
      "% Formulas that are not ordinary clauses:\n",
      "1 (all x (studies(x,exam) -> pass(x,exam))) # label(non_clause).  [assumption].\n",
      "2 pass(Pierre,exam) # label(non_clause) # label(goal).  [goal].\n",
      "\n",
      "============================== end of process non-clausal formulas ===\n",
      "\n",
      "============================== PROCESS INITIAL CLAUSES ===============\n",
      "\n",
      "% Clauses before input processing:\n",
      "\n",
      "formulas(usable).\n",
      "end_of_list.\n",
      "\n",
      "formulas(sos).\n",
      "studies(Pierre,exam).  [assumption].\n",
      "-studies(x,exam) | pass(x,exam).  [clausify(1)].\n",
      "-pass(Pierre,exam).  [deny(2)].\n",
      "end_of_list.\n",
      "\n",
      "formulas(demodulators).\n",
      "end_of_list.\n",
      "\n",
      "============================== PREDICATE ELIMINATION =================\n",
      "\n",
      "Eliminating studies/2\n",
      "3 -studies(x,exam) | pass(x,exam).  [clausify(1)].\n",
      "4 studies(Pierre,exam).  [assumption].\n",
      "Derived: pass(Pierre,exam).  [resolve(3,a,4,a)].\n",
      "\n",
      "Eliminating pass/2\n",
      "5 pass(Pierre,exam).  [resolve(3,a,4,a)].\n",
      "6 -pass(Pierre,exam).  [deny(2)].\n",
      "Derived: $F.  [resolve(5,a,6,a)].\n",
      "\n",
      "============================== end predicate elimination =============\n",
      "\n",
      "Term ordering decisions:\n",
      "Predicate symbol precedence:  predicate_order([ ]).\n",
      "Function symbol precedence:  function_order([ ]).\n",
      "After inverse_order:  (no changes).\n",
      "Unfolding symbols: (none).\n",
      "\n",
      "Auto_inference settings:\n",
      "  % set(neg_binary_resolution).  % (HNE depth_diff=0)\n",
      "  % clear(ordered_res).  % (HNE depth_diff=0)\n",
      "  % set(ur_resolution).  % (HNE depth_diff=0)\n",
      "    % set(ur_resolution) -> set(pos_ur_resolution).\n",
      "    % set(ur_resolution) -> set(neg_ur_resolution).\n",
      "\n",
      "Auto_process settings:  (no changes).\n",
      "\n",
      "\u0007-------- Proof 1 -------- \n",
      "\n",
      "============================== PROOF =================================\n",
      "\n",
      "% Proof 1 at 0.00 (+ 0.01) seconds.\n",
      "% Length of proof is 7.\n",
      "% Level of proof is 3.\n",
      "% Maximum clause weight is 0.000.\n",
      "% Given clauses 0.\n",
      "\n",
      "1 (all x (studies(x,exam) -> pass(x,exam))) # label(non_clause).  [assumption].\n",
      "2 pass(Pierre,exam) # label(non_clause) # label(goal).  [goal].\n",
      "3 -studies(x,exam) | pass(x,exam).  [clausify(1)].\n",
      "4 studies(Pierre,exam).  [assumption].\n",
      "5 pass(Pierre,exam).  [resolve(3,a,4,a)].\n",
      "6 -pass(Pierre,exam).  [deny(2)].\n",
      "7 $F.  [resolve(5,a,6,a)].\n",
      "\n",
      "============================== end of proof ==========================\n",
      "\n",
      "============================== STATISTICS ============================\n",
      "\n",
      "Given=0. Generated=1. Kept=0. proofs=1.\n",
      "Usable=0. Sos=0. Demods=0. Limbo=0, Disabled=5. Hints=0.\n",
      "Kept_by_rule=0, Deleted_by_rule=0.\n",
      "Forward_subsumed=0. Back_subsumed=0.\n",
      "Sos_limit_deleted=0. Sos_displaced=0. Sos_removed=0.\n",
      "New_demodulators=0 (0 lex), Back_demodulated=0. Back_unit_deleted=0.\n",
      "Demod_attempts=0. Demod_rewrites=0.\n",
      "Res_instance_prunes=0. Para_instance_prunes=0. Basic_paramod_prunes=0.\n",
      "Nonunit_fsub_feature_tests=0. Nonunit_bsub_feature_tests=0.\n",
      "Megabytes=0.02.\n",
      "User_CPU=0.00, System_CPU=0.01, Wall_clock=0.\n",
      "\n",
      "============================== end of statistics =====================\n",
      "\n",
      "============================== end of search =========================\n",
      "\n",
      "THEOREM PROVED\n",
      "\n",
      "THEOREM PROVED\n",
      "\n",
      "Exiting with 1 proof.\n",
      "\n",
      "------ process 23032 exit (max_proofs) ------\n",
      "\u0007\n",
      "Process 23032 exit (max_proofs) Mon Jun 19 23:24:40 2017\n",
      " \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prover.prove(goal=test_outcome2, \n",
    "             assumptions=[event2, rule],\n",
    "             verbose=True)               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rover': 'r', 'runs': set([('f',), ('a',)]), 'alex': 'a', 'sleeps': set([('r',), ('g',)]), 'felix': 'f', 'fox': set([('f',)]), 'dog': set([('a',), ('r',)]), 'jumps_over': set([('a', 'g'), ('f', 'g'), ('a', 'r'), ('f', 'r')]), 'cat': set([('g',)]), 'garfield': 'g'}\n"
     ]
    }
   ],
   "source": [
    "# define symbols (entities\\functions) and their values\n",
    "rules = \"\"\"\n",
    "    rover => r\n",
    "    felix => f\n",
    "    garfield => g\n",
    "    alex => a\n",
    "    dog => {r, a}\n",
    "    cat => {g}\n",
    "    fox => {f}\n",
    "    runs => {a, f}\n",
    "    sleeps => {r, g}\n",
    "    jumps_over => {(f, g), (a, g), (f, r), (a, r)}\n",
    "    \"\"\"\n",
    "val = nltk.Valuation.fromstring(rules)\n",
    "\n",
    "print val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "dom = {'r', 'f', 'g', 'a'}\n",
    "m = nltk.Model(dom, val)\n",
    "\n",
    "print m.evaluate('jumps_over(felix, rover) & dog(rover) & runs(rover)', None)\n",
    "print m.evaluate('jumps_over(felix, rover) & dog(rover) & -runs(rover)', None)\n",
    "print m.evaluate('jumps_over(alex, garfield) & dog(alex) & cat(garfield) & sleeps(garfield)', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "g = nltk.Assignment(dom, [('x', 'r'), ('y', 'f')])   \n",
    "print m.evaluate('runs(y) & jumps_over(y, x) & sleeps(x)', g)   \n",
    "print m.evaluate('exists y. (fox(y) & runs(y))', g)     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['a', 'f'])\n"
     ]
    }
   ],
   "source": [
    "formula = read_expr('runs(x)')\n",
    "print m.satisfiers(formula, 'x', g)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['f'])\n"
     ]
    }
   ],
   "source": [
    "formula = read_expr('runs(x) & fox(x)')\n",
    "print m.satisfiers(formula, 'x', g)              \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "def build_feature_matrix(documents, feature_type='frequency',\n",
    "                         ngram_range=(1, 1), min_df=0.0, max_df=1.0):\n",
    "\n",
    "    feature_type = feature_type.lower().strip()  \n",
    "    \n",
    "    if feature_type == 'binary':\n",
    "        vectorizer = CountVectorizer(binary=True, min_df=min_df,\n",
    "                                     max_df=max_df, ngram_range=ngram_range)\n",
    "    elif feature_type == 'frequency':\n",
    "        vectorizer = CountVectorizer(binary=False, min_df=min_df,\n",
    "                                     max_df=max_df, ngram_range=ngram_range)\n",
    "    elif feature_type == 'tfidf':\n",
    "        vectorizer = TfidfVectorizer(min_df=min_df, max_df=max_df, \n",
    "                                     ngram_range=ngram_range)\n",
    "    else:\n",
    "        raise Exception(\"Wrong feature type entered. Possible values: 'binary', 'frequency', 'tfidf'\")\n",
    "\n",
    "    feature_matrix = vectorizer.fit_transform(documents).astype(float)\n",
    "    \n",
    "    return vectorizer, feature_matrix\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def display_evaluation_metrics(true_labels, predicted_labels, positive_class=1):\n",
    "    print 'Accuracy:', np.round(metrics.accuracy_score(true_labels, predicted_labels), 2)\n",
    "    print 'Precision:', np.round(\n",
    "        metrics.precision_score(\n",
    "            true_labels, predicted_labels, pos_label=positive_class, average='binary'), 2)\n",
    "    print 'Recall:', np.round(\n",
    "        metrics.recall_score(\n",
    "            true_labels, predicted_labels, pos_label=positive_class, average='binary'), 2)\n",
    "    print 'F1 Score:', np.round(\n",
    "        metrics.f1_score(\n",
    "            true_labels, predicted_labels, pos_label=positive_class, average='binary'), 2)\n",
    "                        \n",
    "def display_confusion_matrix(true_labels, predicted_labels, classes=[1,0]):\n",
    "    \n",
    "    cm = metrics.confusion_matrix(y_true=true_labels, \n",
    "                                  y_pred=predicted_labels, \n",
    "                                  labels=classes)\n",
    "    cm_frame = pd.DataFrame(data=cm, \n",
    "                            columns=pd.MultiIndex(levels=[['Predicted:'], classes], \n",
    "                                                  labels=[[0,0],[0,1]]), \n",
    "                            index=pd.MultiIndex(levels=[['Actual:'], classes], \n",
    "                                                labels=[[0,0],[0,1]])) \n",
    "    print cm_frame                            \n",
    "\n",
    "\n",
    "def display_classification_report(true_labels, predicted_labels, classes=[1,0]):\n",
    "\n",
    "    report = metrics.classification_report(y_true=true_labels, \n",
    "                                           y_pred=predicted_labels, \n",
    "                                           labels=classes) \n",
    "    print report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Review Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = {'pos': 'positive', 'neg': 'negative'}\n",
    "\n",
    "dataset = pd.DataFrame()\n",
    "for directory in ('test', 'train'):\n",
    "    for sentiment in ('pos', 'neg'):\n",
    "        path =r'/pub/data/aclImdb/{}/{}'.format(directory, sentiment)\n",
    "        for review_file in os.listdir(path):\n",
    "            with open(os.path.join(path, review_file), 'r') as input_file:\n",
    "                review = input_file.read()\n",
    "            dataset = dataset.append([[review, labels[sentiment]]], \n",
    "                                     ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset.columns = ['review', 'sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indices = dataset.index.tolist()\n",
    "np.random.shuffle(indices)\n",
    "indices = np.array(indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = dataset.reindex(index=indices)\n",
    "\n",
    "dataset.to_csv('movie_reviews.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review sentiment\n",
      "0  I have to totally disagree with the other comm...  positive\n",
      "1  Things get dull early an often in this in this...  negative\n",
      "2  I just wish I was eloquent enough to say how G...  positive\n",
      "3  Notorious HK CATIII actor, Anthony Wong, is fo...  positive\n",
      "4  What often threatens to turn into a soppy and ...  positive\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from normalization import normalize_corpus\n",
    "#from utils import build_feature_matrix\n",
    "\n",
    "\n",
    "dataset = pd.read_csv(r'movie_reviews.csv')\n",
    "\n",
    "print dataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"Got into this flick, just as it was beginning, on an afternoon where I was home with a touch of flu - otherwise I'd have missed it. That probably would have been best.<br /><br />I noticed the presence of Lindsay Crouse and Jay Thomas - both very good performers - and thought this might be worth a look. It proved to be to some extent, but only because it is one of those stories so awful it fascinates.<br /><br />Zoe McLellan has little to recommend her talents, except for her Jayne Mansfield- or Loni Anderson-like bosom. Unfortunately, her acting prowess - at least here - makes Mansfield and Anderson seem to be Garbo or Davis by comparison.<br /><br />The young nut case's white rat, the owner's cat, the young nut case having the owner evicted and restrained in her own home, and a bunch of doophus's (including the young nut case) running around a bio hazard facility, and the absurd conclusion. I kept waiting for at least some scene or plot element to contain at least a modicum of realism, believability or being capable of evoking some empathy/sympathy -- but this proved to be in vain.\",\n",
       "  'negative'),\n",
       " ('I think this movie is amazing but there is one problem. there is one song that i want to find but cannot find it. it starts on about 18 minutes just after the coach has said \"what are u the runt of the family\", and then looks at the fat kid takes his hat off then he says go, the song that starts there, i would like to know what it is? Does any 1 no email me please or add a comment.It Starts Zaga Zow, Ziga Zow something along those lines. I just think it is an amazing dance track i would love to have that song so that i could use it in my break dancing lessons. It starts when they are jumping and running over the orange fast stepper things which are used in football training to help you run faster',\n",
       "  'positive'),\n",
       " ('I recently picked up all three Robocop films in one box set, rather cheaply and the only reason I did this was for the special edition of the superb first one. I have seen Robocop 2 before but not for 17 years, the year it came out. I have never watched it since because I can still remember how disappointed I was when I discovered how appalling it really is. Its a complete mess really, it has all the signs of a troubled production with so many sub-plots going on at the same time. It has a very uneven tone also and it is also one of the nastiest films I have ever seen. I don\\'t mind a little violence, the first one was incredibly violent but this one is just plain nasty. Also the SFX is terrible even for 1990, say hello to bad stop motion. Also having a drug dealing, cursing kid as a villain is just a little too much. Peter Weller at least had the common sense not to return for the next one. The only positive thing I can say for this film is it does have a couple of nice gags, like the thank you for not smoking one and the kiddie baseball team robbing an electrics store. To quote the kid who plays the villain \"It sucks\"',\n",
       "  'negative'),\n",
       " (\"This is a little film with a big heart. Excellent acting throughout and directed with love. If you missed it in theatres (and who didn't?), catch it with someone you love. Frankly, I cried! And I'm a guy, for cryin' out loud!\",\n",
       "  'positive'),\n",
       " (\"I watched this movie and all I can say is this...I am not a film student, nor am I some artsy intellect who tries to look for a deeper meaning into everything that I don't understand. However, IF I were to do that with this film, my thoughts would be...<br /><br />Yep! He's on drugs and I can picture it now...he was tripping one night and sat around with his buddies laughing and saying stuff like, hey...wouldn't it be funny if nuns really could fly? Like what if one just fell out of a plane and free fell for a while, bounced to the ground and got up and walked away? *cackles* or if buckwheat gave the pope a bath? oh my god, I'm cracking up just thinking about it! Dude! We gotta make a movie about it! And then he says to his friend as he's laughing...Oh and wouldn't it be hilarious if people loved it and called me a genius for it? So to me, this is what happens when some guy does one too many drugs and writes a script and produces a movie. Should I have been doing LSD to understand what this guy was thinking so I could have had a laugh too? Because I have to tell you, I wasn't laughing. I was yawning and checking the time.<br /><br />I think everyone who is trying their hardest to find a deeper meaning is hysterical. I had never heard of this director until I came to read the reviews, which I did because I was mad that I lost that last 2 hrs, or how ever long it was, (it felt like 12 hrs of my life) and I can't ever get it back, anyway...I have read that this guy is a heroine addict and he wanted to die for art?? what the heck is that? So my point is sort of proved. This guy is not all there, he's a drug addict, and his movie is evidence of such...So please quit trying to find a deeper meaning to it. If one really wants to understand everything in this movie, go drop some LSD and sit back and relax, then it might actually make sense.<br /><br />It reminded me of the time I watched Gus Van Sant's Last Days, another movie I was mad about watching. I cannot help but wonder what the ratings would be for that movie, if the same people reviewed it who reviewed this one. It seems like, if the movie's director is totally off his rocker, or if it's a french movie with sex and subtitles, or if it's a cartoon, it is going to get great reviews, hands down, anything else is boring and has already been done. BLAH, bring on the boring please!\",\n",
       "  'negative'),\n",
       " (\"Whoever thought that ANOTHER Home Alone film would be a good idea should have their head examined... Same plot, different kid, more villains (which leads to MORE endless stupidity in the traps). The other two films were bad enough, and this is where it hits rock bottom. People may as well watch the other films for plot, as it's all identical.\",\n",
       "  'negative'),\n",
       " (\"Great movie. Good acting ,a wonderful script. It's exciting to find out what the people are thinking and how they react on the situation they are in. A pity about the ending; a 'page' of text of how Nynke's life went on, instead of moving images was a poor choice. I hope this movie attracts a lot of people; it's worth it!\",\n",
       "  'positive'),\n",
       " ('i wish i could find some good things to say about this animated sequel(but not really a sequel)to \"Atlantis:The Lost Empire\"but this would be a very short comment.the magic that the first one had is nowhere to be found here.the animation is pretty poor all over,the characters themselves are not very well drawn.the backgrounds and the foregrounds are also not good.there\\'s very little attention to detail here.and instead of a compelling and engaging story,we have 3 short stories which are boring and don\\'t make a lot of sense.i swear,even the characters sounded like they were bored,and would rather be somewhere else.which says that the voice actors were bored and wanted to be someplace else,at least that\\'s the impression.some of the same actors return for this dismal effort,but an integral par of the success of the first one was Michael J.Fox as the main hero, Milo Thatch.i get the distinct impression this movie was just thrown together to capitalize on the success of the first one,without much thought or care.but at least Cree Summer returns as the voice of \"Kida\".that\\'s probably the only good thing about this movie,and even she doesn\\'t seem to have her heart completely in it.mind you,i guess you couldn\\'t blame any of the cast for not giving their all,considering what they had to work with.or rather not work with.this is a straight to video movie(and i use the term loosely)which should have went straight to the nearest landfill.anyway,shame on Disney.consumers deserve much better than this.this one gets a 0/10 and a well deserved one at that.p.u',\n",
       "  'negative')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = dataset[:35000]\n",
    "test_data = dataset[35000:]\n",
    "\n",
    "train_reviews = np.array(train_data['review'])\n",
    "train_sentiments = np.array(train_data['sentiment'])\n",
    "test_reviews = np.array(test_data['review'])\n",
    "test_sentiments = np.array(test_data['sentiment'])\n",
    "\n",
    "\n",
    "sample_docs = [100, 5817, 7626, 7356, 1008, 7155, 3533, 13010]\n",
    "sample_data = [(test_reviews[index],\n",
    "                test_sentiments[index])\n",
    "                  for index in sample_docs]\n",
    "\n",
    "sample_data    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Machine Learning Technique\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# normalization\n",
    "norm_train_reviews = normalize_corpus(train_reviews,\n",
    "                                      lemmatize=True,\n",
    "                                      only_text_chars=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# feature extraction                                                                            \n",
    "vectorizer, train_features = build_feature_matrix(documents=norm_train_reviews,\n",
    "                                                  feature_type='tfidf',\n",
    "                                                  ngram_range=(1, 1), \n",
    "                                                  min_df=0.0, max_df=1.0)                                      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', n_iter=500, n_jobs=1,\n",
       "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "# build the model\n",
    "svm = SGDClassifier(loss='hinge', n_iter=500)\n",
    "svm.fit(train_features, train_sentiments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize reviews                        \n",
    "norm_test_reviews = normalize_corpus(test_reviews,\n",
    "                                     lemmatize=True,\n",
    "                                     only_text_chars=True)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review:-\n",
      "Got into this flick, just as it was beginning, on an afternoon where I was home with a touch of flu - otherwise I'd have missed it. That probably would have been best.<br /><br />I noticed the presence of Lindsay Crouse and Jay Thomas - both very good performers - and thought this might be worth a look. It proved to be to some extent, but only because it is one of those stories so awful it fascinates.<br /><br />Zoe McLellan has little to recommend her talents, except for her Jayne Mansfield- or Loni Anderson-like bosom. Unfortunately, her acting prowess - at least here - makes Mansfield and Anderson seem to be Garbo or Davis by comparison.<br /><br />The young nut case's white rat, the owner's cat, the young nut case having the owner evicted and restrained in her own home, and a bunch of doophus's (including the young nut case) running around a bio hazard facility, and the absurd conclusion. I kept waiting for at least some scene or plot element to contain at least a modicum of realism, believability or being capable of evoking some empathy/sympathy -- but this proved to be in vain.\n",
      "Actual Labeled Sentiment: negative\n",
      "Predicted Sentiment: negative\n",
      "\n",
      "Review:-\n",
      "I think this movie is amazing but there is one problem. there is one song that i want to find but cannot find it. it starts on about 18 minutes just after the coach has said \"what are u the runt of the family\", and then looks at the fat kid takes his hat off then he says go, the song that starts there, i would like to know what it is? Does any 1 no email me please or add a comment.It Starts Zaga Zow, Ziga Zow something along those lines. I just think it is an amazing dance track i would love to have that song so that i could use it in my break dancing lessons. It starts when they are jumping and running over the orange fast stepper things which are used in football training to help you run faster\n",
      "Actual Labeled Sentiment: positive\n",
      "Predicted Sentiment: negative\n",
      "\n",
      "Review:-\n",
      "I recently picked up all three Robocop films in one box set, rather cheaply and the only reason I did this was for the special edition of the superb first one. I have seen Robocop 2 before but not for 17 years, the year it came out. I have never watched it since because I can still remember how disappointed I was when I discovered how appalling it really is. Its a complete mess really, it has all the signs of a troubled production with so many sub-plots going on at the same time. It has a very uneven tone also and it is also one of the nastiest films I have ever seen. I don't mind a little violence, the first one was incredibly violent but this one is just plain nasty. Also the SFX is terrible even for 1990, say hello to bad stop motion. Also having a drug dealing, cursing kid as a villain is just a little too much. Peter Weller at least had the common sense not to return for the next one. The only positive thing I can say for this film is it does have a couple of nice gags, like the thank you for not smoking one and the kiddie baseball team robbing an electrics store. To quote the kid who plays the villain \"It sucks\"\n",
      "Actual Labeled Sentiment: negative\n",
      "Predicted Sentiment: negative\n",
      "\n",
      "Review:-\n",
      "This is a little film with a big heart. Excellent acting throughout and directed with love. If you missed it in theatres (and who didn't?), catch it with someone you love. Frankly, I cried! And I'm a guy, for cryin' out loud!\n",
      "Actual Labeled Sentiment: positive\n",
      "Predicted Sentiment: positive\n",
      "\n",
      "Review:-\n",
      "I watched this movie and all I can say is this...I am not a film student, nor am I some artsy intellect who tries to look for a deeper meaning into everything that I don't understand. However, IF I were to do that with this film, my thoughts would be...<br /><br />Yep! He's on drugs and I can picture it now...he was tripping one night and sat around with his buddies laughing and saying stuff like, hey...wouldn't it be funny if nuns really could fly? Like what if one just fell out of a plane and free fell for a while, bounced to the ground and got up and walked away? *cackles* or if buckwheat gave the pope a bath? oh my god, I'm cracking up just thinking about it! Dude! We gotta make a movie about it! And then he says to his friend as he's laughing...Oh and wouldn't it be hilarious if people loved it and called me a genius for it? So to me, this is what happens when some guy does one too many drugs and writes a script and produces a movie. Should I have been doing LSD to understand what this guy was thinking so I could have had a laugh too? Because I have to tell you, I wasn't laughing. I was yawning and checking the time.<br /><br />I think everyone who is trying their hardest to find a deeper meaning is hysterical. I had never heard of this director until I came to read the reviews, which I did because I was mad that I lost that last 2 hrs, or how ever long it was, (it felt like 12 hrs of my life) and I can't ever get it back, anyway...I have read that this guy is a heroine addict and he wanted to die for art?? what the heck is that? So my point is sort of proved. This guy is not all there, he's a drug addict, and his movie is evidence of such...So please quit trying to find a deeper meaning to it. If one really wants to understand everything in this movie, go drop some LSD and sit back and relax, then it might actually make sense.<br /><br />It reminded me of the time I watched Gus Van Sant's Last Days, another movie I was mad about watching. I cannot help but wonder what the ratings would be for that movie, if the same people reviewed it who reviewed this one. It seems like, if the movie's director is totally off his rocker, or if it's a french movie with sex and subtitles, or if it's a cartoon, it is going to get great reviews, hands down, anything else is boring and has already been done. BLAH, bring on the boring please!\n",
      "Actual Labeled Sentiment: negative\n",
      "Predicted Sentiment: negative\n",
      "\n",
      "Review:-\n",
      "Whoever thought that ANOTHER Home Alone film would be a good idea should have their head examined... Same plot, different kid, more villains (which leads to MORE endless stupidity in the traps). The other two films were bad enough, and this is where it hits rock bottom. People may as well watch the other films for plot, as it's all identical.\n",
      "Actual Labeled Sentiment: negative\n",
      "Predicted Sentiment: negative\n",
      "\n",
      "Review:-\n",
      "Great movie. Good acting ,a wonderful script. It's exciting to find out what the people are thinking and how they react on the situation they are in. A pity about the ending; a 'page' of text of how Nynke's life went on, instead of moving images was a poor choice. I hope this movie attracts a lot of people; it's worth it!\n",
      "Actual Labeled Sentiment: positive\n",
      "Predicted Sentiment: positive\n",
      "\n",
      "Review:-\n",
      "i wish i could find some good things to say about this animated sequel(but not really a sequel)to \"Atlantis:The Lost Empire\"but this would be a very short comment.the magic that the first one had is nowhere to be found here.the animation is pretty poor all over,the characters themselves are not very well drawn.the backgrounds and the foregrounds are also not good.there's very little attention to detail here.and instead of a compelling and engaging story,we have 3 short stories which are boring and don't make a lot of sense.i swear,even the characters sounded like they were bored,and would rather be somewhere else.which says that the voice actors were bored and wanted to be someplace else,at least that's the impression.some of the same actors return for this dismal effort,but an integral par of the success of the first one was Michael J.Fox as the main hero, Milo Thatch.i get the distinct impression this movie was just thrown together to capitalize on the success of the first one,without much thought or care.but at least Cree Summer returns as the voice of \"Kida\".that's probably the only good thing about this movie,and even she doesn't seem to have her heart completely in it.mind you,i guess you couldn't blame any of the cast for not giving their all,considering what they had to work with.or rather not work with.this is a straight to video movie(and i use the term loosely)which should have went straight to the nearest landfill.anyway,shame on Disney.consumers deserve much better than this.this one gets a 0/10 and a well deserved one at that.p.u\n",
      "Actual Labeled Sentiment: negative\n",
      "Predicted Sentiment: negative\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# extract features                                     \n",
    "test_features = vectorizer.transform(norm_test_reviews)         \n",
    "\n",
    "\n",
    "for doc_index in sample_docs:\n",
    "    print 'Review:-'\n",
    "    print test_reviews[doc_index]\n",
    "    print 'Actual Labeled Sentiment:', test_sentiments[doc_index]\n",
    "    doc_features = test_features[doc_index]\n",
    "    predicted_sentiment = svm.predict(doc_features)[0]\n",
    "    print 'Predicted Sentiment:', predicted_sentiment\n",
    "    print\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.89\n",
      "Precision: 0.88\n",
      "Recall: 0.91\n",
      "F1 Score: 0.89\n"
     ]
    }
   ],
   "source": [
    "predicted_sentiments = svm.predict(test_features)       \n",
    "\n",
    "#from utils import display_evaluation_metrics, display_confusion_matrix, display_classification_report\n",
    "\n",
    "display_evaluation_metrics(true_labels=test_sentiments,\n",
    "                           predicted_labels=predicted_sentiments,\n",
    "                           positive_class='positive')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Predicted:         \n",
      "                   positive negative\n",
      "Actual: positive       6854      704\n",
      "        negative        937     6505\n"
     ]
    }
   ],
   "source": [
    "display_confusion_matrix(true_labels=test_sentiments,\n",
    "                         predicted_labels=predicted_sentiments,\n",
    "                         classes=['positive', 'negative'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive       0.88      0.91      0.89      7558\n",
      "   negative       0.90      0.87      0.89      7442\n",
      "\n",
      "avg / total       0.89      0.89      0.89     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "display_classification_report(true_labels=test_sentiments,\n",
    "                              predicted_labels=predicted_sentiments,\n",
    "                              classes=['positive', 'negative'])                         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Lexicon-based Techniques\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AFINN Lexicon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install afinn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.0\n",
      "-5.0\n"
     ]
    }
   ],
   "source": [
    "from afinn import Afinn\n",
    "afn = Afinn(emoticons=True) \n",
    "print afn.score('I really hated the plot of this movie')\n",
    "\n",
    "print afn.score('I really hated the plot of this movie :(')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SentiWordNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Polarity Score: 0.5\n",
      "Negative Polarity Score: 0.0\n",
      "Objective Score: 0.5\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "\n",
    "good = swn.senti_synsets('good', 'n')[0]\n",
    "print 'Positive Polarity Score:', good.pos_score()\n",
    "print 'Negative Polarity Score:', good.neg_score()\n",
    "print 'Objective Score:', good.obj_score()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from normalization import normalize_accented_characters, html_parser, strip_html\n",
    "\n",
    "def analyze_sentiment_sentiwordnet_lexicon(review,\n",
    "                                           verbose=False):\n",
    "    # pre-process text\n",
    "    review = normalize_accented_characters(review)\n",
    "    review = html_parser.unescape(review)\n",
    "    review = strip_html(review)\n",
    "    # tokenize and POS tag text tokens\n",
    "    text_tokens = nltk.word_tokenize(review)\n",
    "    tagged_text = nltk.pos_tag(text_tokens)\n",
    "    pos_score = neg_score = token_count = obj_score = 0\n",
    "    # get wordnet synsets based on POS tags\n",
    "    # get sentiment scores if synsets are found\n",
    "    for word, tag in tagged_text:\n",
    "        ss_set = None\n",
    "        if 'NN' in tag and swn.senti_synsets(word, 'n'):\n",
    "            ss_set = swn.senti_synsets(word, 'n')[0]\n",
    "        elif 'VB' in tag and swn.senti_synsets(word, 'v'):\n",
    "            ss_set = swn.senti_synsets(word, 'v')[0]\n",
    "        elif 'JJ' in tag and swn.senti_synsets(word, 'a'):\n",
    "            ss_set = swn.senti_synsets(word, 'a')[0]\n",
    "        elif 'RB' in tag and swn.senti_synsets(word, 'r'):\n",
    "            ss_set = swn.senti_synsets(word, 'r')[0]\n",
    "        # if senti-synset is found        \n",
    "        if ss_set:\n",
    "            # add scores for all found synsets\n",
    "            pos_score += ss_set.pos_score()\n",
    "            neg_score += ss_set.neg_score()\n",
    "            obj_score += ss_set.obj_score()\n",
    "            token_count += 1\n",
    "    \n",
    "    # aggregate final scores\n",
    "    final_score = pos_score - neg_score\n",
    "    norm_final_score = round(float(final_score) / token_count, 2)\n",
    "    final_sentiment = 'positive' if norm_final_score >= 0 else 'negative'\n",
    "    if verbose:\n",
    "        norm_obj_score = round(float(obj_score) / token_count, 2)\n",
    "        norm_pos_score = round(float(pos_score) / token_count, 2)\n",
    "        norm_neg_score = round(float(neg_score) / token_count, 2)\n",
    "        # to display results in a nice table\n",
    "        sentiment_frame = pd.DataFrame([[final_sentiment, norm_obj_score,\n",
    "                                         norm_pos_score, norm_neg_score,\n",
    "                                         norm_final_score]],\n",
    "                                         columns=pd.MultiIndex(levels=[['SENTIMENT STATS:'], \n",
    "                                                                      ['Predicted Sentiment', 'Objectivity',\n",
    "                                                                       'Positive', 'Negative', 'Overall']], \n",
    "                                                              labels=[[0,0,0,0,0],[0,1,2,3,4]]))\n",
    "        print sentiment_frame\n",
    "        \n",
    "    return final_sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review:\n",
      "Got into this flick, just as it was beginning, on an afternoon where I was home with a touch of flu - otherwise I'd have missed it. That probably would have been best.<br /><br />I noticed the presence of Lindsay Crouse and Jay Thomas - both very good performers - and thought this might be worth a look. It proved to be to some extent, but only because it is one of those stories so awful it fascinates.<br /><br />Zoe McLellan has little to recommend her talents, except for her Jayne Mansfield- or Loni Anderson-like bosom. Unfortunately, her acting prowess - at least here - makes Mansfield and Anderson seem to be Garbo or Davis by comparison.<br /><br />The young nut case's white rat, the owner's cat, the young nut case having the owner evicted and restrained in her own home, and a bunch of doophus's (including the young nut case) running around a bio hazard facility, and the absurd conclusion. I kept waiting for at least some scene or plot element to contain at least a modicum of realism, believability or being capable of evoking some empathy/sympathy -- but this proved to be in vain.\n",
      "\n",
      "Labeled Sentiment: negative\n",
      "\n",
      "     SENTIMENT STATS:                                      \n",
      "  Predicted Sentiment Objectivity Positive Negative Overall\n",
      "0            positive        0.86     0.07     0.07     0.0\n",
      "------------------------------------------------------------\n",
      "Review:\n",
      "I think this movie is amazing but there is one problem. there is one song that i want to find but cannot find it. it starts on about 18 minutes just after the coach has said \"what are u the runt of the family\", and then looks at the fat kid takes his hat off then he says go, the song that starts there, i would like to know what it is? Does any 1 no email me please or add a comment.It Starts Zaga Zow, Ziga Zow something along those lines. I just think it is an amazing dance track i would love to have that song so that i could use it in my break dancing lessons. It starts when they are jumping and running over the orange fast stepper things which are used in football training to help you run faster\n",
      "\n",
      "Labeled Sentiment: positive\n",
      "\n",
      "     SENTIMENT STATS:                                      \n",
      "  Predicted Sentiment Objectivity Positive Negative Overall\n",
      "0            positive         0.9     0.06     0.04    0.02\n",
      "------------------------------------------------------------\n",
      "Review:\n",
      "I recently picked up all three Robocop films in one box set, rather cheaply and the only reason I did this was for the special edition of the superb first one. I have seen Robocop 2 before but not for 17 years, the year it came out. I have never watched it since because I can still remember how disappointed I was when I discovered how appalling it really is. Its a complete mess really, it has all the signs of a troubled production with so many sub-plots going on at the same time. It has a very uneven tone also and it is also one of the nastiest films I have ever seen. I don't mind a little violence, the first one was incredibly violent but this one is just plain nasty. Also the SFX is terrible even for 1990, say hello to bad stop motion. Also having a drug dealing, cursing kid as a villain is just a little too much. Peter Weller at least had the common sense not to return for the next one. The only positive thing I can say for this film is it does have a couple of nice gags, like the thank you for not smoking one and the kiddie baseball team robbing an electrics store. To quote the kid who plays the villain \"It sucks\"\n",
      "\n",
      "Labeled Sentiment: negative\n",
      "\n",
      "     SENTIMENT STATS:                                      \n",
      "  Predicted Sentiment Objectivity Positive Negative Overall\n",
      "0            negative         0.8     0.08     0.11   -0.03\n",
      "------------------------------------------------------------\n",
      "Review:\n",
      "This is a little film with a big heart. Excellent acting throughout and directed with love. If you missed it in theatres (and who didn't?), catch it with someone you love. Frankly, I cried! And I'm a guy, for cryin' out loud!\n",
      "\n",
      "Labeled Sentiment: positive\n",
      "\n",
      "     SENTIMENT STATS:                                      \n",
      "  Predicted Sentiment Objectivity Positive Negative Overall\n",
      "0            positive        0.79     0.15     0.06     0.1\n",
      "------------------------------------------------------------\n",
      "Review:\n",
      "I watched this movie and all I can say is this...I am not a film student, nor am I some artsy intellect who tries to look for a deeper meaning into everything that I don't understand. However, IF I were to do that with this film, my thoughts would be...<br /><br />Yep! He's on drugs and I can picture it now...he was tripping one night and sat around with his buddies laughing and saying stuff like, hey...wouldn't it be funny if nuns really could fly? Like what if one just fell out of a plane and free fell for a while, bounced to the ground and got up and walked away? *cackles* or if buckwheat gave the pope a bath? oh my god, I'm cracking up just thinking about it! Dude! We gotta make a movie about it! And then he says to his friend as he's laughing...Oh and wouldn't it be hilarious if people loved it and called me a genius for it? So to me, this is what happens when some guy does one too many drugs and writes a script and produces a movie. Should I have been doing LSD to understand what this guy was thinking so I could have had a laugh too? Because I have to tell you, I wasn't laughing. I was yawning and checking the time.<br /><br />I think everyone who is trying their hardest to find a deeper meaning is hysterical. I had never heard of this director until I came to read the reviews, which I did because I was mad that I lost that last 2 hrs, or how ever long it was, (it felt like 12 hrs of my life) and I can't ever get it back, anyway...I have read that this guy is a heroine addict and he wanted to die for art?? what the heck is that? So my point is sort of proved. This guy is not all there, he's a drug addict, and his movie is evidence of such...So please quit trying to find a deeper meaning to it. If one really wants to understand everything in this movie, go drop some LSD and sit back and relax, then it might actually make sense.<br /><br />It reminded me of the time I watched Gus Van Sant's Last Days, another movie I was mad about watching. I cannot help but wonder what the ratings would be for that movie, if the same people reviewed it who reviewed this one. It seems like, if the movie's director is totally off his rocker, or if it's a french movie with sex and subtitles, or if it's a cartoon, it is going to get great reviews, hands down, anything else is boring and has already been done. BLAH, bring on the boring please!\n",
      "\n",
      "Labeled Sentiment: negative\n",
      "\n",
      "     SENTIMENT STATS:                                      \n",
      "  Predicted Sentiment Objectivity Positive Negative Overall\n",
      "0            positive        0.86     0.09     0.05    0.04\n",
      "------------------------------------------------------------\n",
      "Review:\n",
      "Whoever thought that ANOTHER Home Alone film would be a good idea should have their head examined... Same plot, different kid, more villains (which leads to MORE endless stupidity in the traps). The other two films were bad enough, and this is where it hits rock bottom. People may as well watch the other films for plot, as it's all identical.\n",
      "\n",
      "Labeled Sentiment: negative\n",
      "\n",
      "     SENTIMENT STATS:                                      \n",
      "  Predicted Sentiment Objectivity Positive Negative Overall\n",
      "0            negative        0.79     0.09     0.11   -0.02\n",
      "------------------------------------------------------------\n",
      "Review:\n",
      "Great movie. Good acting ,a wonderful script. It's exciting to find out what the people are thinking and how they react on the situation they are in. A pity about the ending; a 'page' of text of how Nynke's life went on, instead of moving images was a poor choice. I hope this movie attracts a lot of people; it's worth it!\n",
      "\n",
      "Labeled Sentiment: positive\n",
      "\n",
      "     SENTIMENT STATS:                                      \n",
      "  Predicted Sentiment Objectivity Positive Negative Overall\n",
      "0            positive        0.82      0.1     0.08    0.01\n",
      "------------------------------------------------------------\n",
      "Review:\n",
      "i wish i could find some good things to say about this animated sequel(but not really a sequel)to \"Atlantis:The Lost Empire\"but this would be a very short comment.the magic that the first one had is nowhere to be found here.the animation is pretty poor all over,the characters themselves are not very well drawn.the backgrounds and the foregrounds are also not good.there's very little attention to detail here.and instead of a compelling and engaging story,we have 3 short stories which are boring and don't make a lot of sense.i swear,even the characters sounded like they were bored,and would rather be somewhere else.which says that the voice actors were bored and wanted to be someplace else,at least that's the impression.some of the same actors return for this dismal effort,but an integral par of the success of the first one was Michael J.Fox as the main hero, Milo Thatch.i get the distinct impression this movie was just thrown together to capitalize on the success of the first one,without much thought or care.but at least Cree Summer returns as the voice of \"Kida\".that's probably the only good thing about this movie,and even she doesn't seem to have her heart completely in it.mind you,i guess you couldn't blame any of the cast for not giving their all,considering what they had to work with.or rather not work with.this is a straight to video movie(and i use the term loosely)which should have went straight to the nearest landfill.anyway,shame on Disney.consumers deserve much better than this.this one gets a 0/10 and a well deserved one at that.p.u\n",
      "\n",
      "Labeled Sentiment: negative\n",
      "\n",
      "     SENTIMENT STATS:                                      \n",
      "  Predicted Sentiment Objectivity Positive Negative Overall\n",
      "0            positive        0.79     0.12     0.09    0.04\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for review, review_sentiment in sample_data:  \n",
    "    print 'Review:'\n",
    "    print review\n",
    "    print\n",
    "    print 'Labeled Sentiment:', review_sentiment    \n",
    "    print    \n",
    "    final_sentiment = analyze_sentiment_sentiwordnet_lexicon(review, verbose=True)\n",
    "    print '-'*60                                                         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance metrics:\n",
      "Accuracy: 0.6\n",
      "Precision: 0.56\n",
      "Recall: 0.92\n",
      "F1 Score: 0.7\n"
     ]
    }
   ],
   "source": [
    "sentiwordnet_predictions = [analyze_sentiment_sentiwordnet_lexicon(review)\n",
    "                            for review in test_reviews]\n",
    "\n",
    "#from utils import display_evaluation_metrics, display_confusion_matrix, display_classification_report\n",
    "\n",
    "print 'Performance metrics:'\n",
    "display_evaluation_metrics(true_labels=test_sentiments,\n",
    "                           predicted_labels=sentiwordnet_predictions,\n",
    "                           positive_class='positive')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "                 Predicted:         \n",
      "                   positive negative\n",
      "Actual: positive       6948      610\n",
      "        negative       5407     2035\n"
     ]
    }
   ],
   "source": [
    "print '\\nConfusion Matrix:'                           \n",
    "display_confusion_matrix(true_labels=test_sentiments,\n",
    "                         predicted_labels=sentiwordnet_predictions,\n",
    "                         classes=['positive', 'negative'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive       0.56      0.92      0.70      7558\n",
      "   negative       0.77      0.27      0.40      7442\n",
      "\n",
      "avg / total       0.67      0.60      0.55     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print '\\nClassification report:'                         \n",
    "display_classification_report(true_labels=test_sentiments,\n",
    "                              predicted_labels=sentiwordnet_predictions,\n",
    "                              classes=['positive', 'negative'])  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VADER Lexicon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pub/anaconda3/envs/python2/lib/python2.7/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "def analyze_sentiment_vader_lexicon(review, \n",
    "                                    threshold=0.1,\n",
    "                                    verbose=False):\n",
    "    # pre-process text\n",
    "    review = normalize_accented_characters(review)\n",
    "    review = html_parser.unescape(review)\n",
    "    review = strip_html(review)\n",
    "    # analyze the sentiment for review\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    scores = analyzer.polarity_scores(review)\n",
    "    # get aggregate scores and final sentiment\n",
    "    agg_score = scores['compound']\n",
    "    final_sentiment = 'positive' if agg_score >= threshold\\\n",
    "                                   else 'negative'\n",
    "    if verbose:\n",
    "        # display detailed sentiment statistics\n",
    "        positive = str(round(scores['pos'], 2)*100)+'%'\n",
    "        final = round(agg_score, 2)\n",
    "        negative = str(round(scores['neg'], 2)*100)+'%'\n",
    "        neutral = str(round(scores['neu'], 2)*100)+'%'\n",
    "        sentiment_frame = pd.DataFrame([[final_sentiment, final, positive,\n",
    "                                        negative, neutral]],\n",
    "                                        columns=pd.MultiIndex(levels=[['SENTIMENT STATS:'], \n",
    "                                                                      ['Predicted Sentiment', 'Polarity Score',\n",
    "                                                                       'Positive', 'Negative',\n",
    "                                                                       'Neutral']], \n",
    "                                                              labels=[[0,0,0,0,0],[0,1,2,3,4]]))\n",
    "        print sentiment_frame\n",
    "    \n",
    "    return final_sentiment\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review:\n",
      "Got into this flick, just as it was beginning, on an afternoon where I was home with a touch of flu - otherwise I'd have missed it. That probably would have been best.<br /><br />I noticed the presence of Lindsay Crouse and Jay Thomas - both very good performers - and thought this might be worth a look. It proved to be to some extent, but only because it is one of those stories so awful it fascinates.<br /><br />Zoe McLellan has little to recommend her talents, except for her Jayne Mansfield- or Loni Anderson-like bosom. Unfortunately, her acting prowess - at least here - makes Mansfield and Anderson seem to be Garbo or Davis by comparison.<br /><br />The young nut case's white rat, the owner's cat, the young nut case having the owner evicted and restrained in her own home, and a bunch of doophus's (including the young nut case) running around a bio hazard facility, and the absurd conclusion. I kept waiting for at least some scene or plot element to contain at least a modicum of realism, believability or being capable of evoking some empathy/sympathy -- but this proved to be in vain.\n",
      "\n",
      "Labeled Sentiment: negative\n",
      "\n",
      "     SENTIMENT STATS:                                         \n",
      "  Predicted Sentiment Polarity Score Positive Negative Neutral\n",
      "0            positive            0.4    10.0%     8.0%   83.0%\n",
      "------------------------------------------------------------\n",
      "Review:\n",
      "I think this movie is amazing but there is one problem. there is one song that i want to find but cannot find it. it starts on about 18 minutes just after the coach has said \"what are u the runt of the family\", and then looks at the fat kid takes his hat off then he says go, the song that starts there, i would like to know what it is? Does any 1 no email me please or add a comment.It Starts Zaga Zow, Ziga Zow something along those lines. I just think it is an amazing dance track i would love to have that song so that i could use it in my break dancing lessons. It starts when they are jumping and running over the orange fast stepper things which are used in football training to help you run faster\n",
      "\n",
      "Labeled Sentiment: positive\n",
      "\n",
      "     SENTIMENT STATS:                                         \n",
      "  Predicted Sentiment Polarity Score Positive Negative Neutral\n",
      "0            positive           0.96    16.0%     4.0%   80.0%\n",
      "------------------------------------------------------------\n",
      "Review:\n",
      "I recently picked up all three Robocop films in one box set, rather cheaply and the only reason I did this was for the special edition of the superb first one. I have seen Robocop 2 before but not for 17 years, the year it came out. I have never watched it since because I can still remember how disappointed I was when I discovered how appalling it really is. Its a complete mess really, it has all the signs of a troubled production with so many sub-plots going on at the same time. It has a very uneven tone also and it is also one of the nastiest films I have ever seen. I don't mind a little violence, the first one was incredibly violent but this one is just plain nasty. Also the SFX is terrible even for 1990, say hello to bad stop motion. Also having a drug dealing, cursing kid as a villain is just a little too much. Peter Weller at least had the common sense not to return for the next one. The only positive thing I can say for this film is it does have a couple of nice gags, like the thank you for not smoking one and the kiddie baseball team robbing an electrics store. To quote the kid who plays the villain \"It sucks\"\n",
      "\n",
      "Labeled Sentiment: negative\n",
      "\n",
      "     SENTIMENT STATS:                                         \n",
      "  Predicted Sentiment Polarity Score Positive Negative Neutral\n",
      "0            negative          -0.99    10.0%    21.0%   69.0%\n",
      "------------------------------------------------------------\n",
      "Review:\n",
      "This is a little film with a big heart. Excellent acting throughout and directed with love. If you missed it in theatres (and who didn't?), catch it with someone you love. Frankly, I cried! And I'm a guy, for cryin' out loud!\n",
      "\n",
      "Labeled Sentiment: positive\n",
      "\n",
      "     SENTIMENT STATS:                                         \n",
      "  Predicted Sentiment Polarity Score Positive Negative Neutral\n",
      "0            positive           0.87    25.0%    10.0%   65.0%\n",
      "------------------------------------------------------------\n",
      "Review:\n",
      "I watched this movie and all I can say is this...I am not a film student, nor am I some artsy intellect who tries to look for a deeper meaning into everything that I don't understand. However, IF I were to do that with this film, my thoughts would be...<br /><br />Yep! He's on drugs and I can picture it now...he was tripping one night and sat around with his buddies laughing and saying stuff like, hey...wouldn't it be funny if nuns really could fly? Like what if one just fell out of a plane and free fell for a while, bounced to the ground and got up and walked away? *cackles* or if buckwheat gave the pope a bath? oh my god, I'm cracking up just thinking about it! Dude! We gotta make a movie about it! And then he says to his friend as he's laughing...Oh and wouldn't it be hilarious if people loved it and called me a genius for it? So to me, this is what happens when some guy does one too many drugs and writes a script and produces a movie. Should I have been doing LSD to understand what this guy was thinking so I could have had a laugh too? Because I have to tell you, I wasn't laughing. I was yawning and checking the time.<br /><br />I think everyone who is trying their hardest to find a deeper meaning is hysterical. I had never heard of this director until I came to read the reviews, which I did because I was mad that I lost that last 2 hrs, or how ever long it was, (it felt like 12 hrs of my life) and I can't ever get it back, anyway...I have read that this guy is a heroine addict and he wanted to die for art?? what the heck is that? So my point is sort of proved. This guy is not all there, he's a drug addict, and his movie is evidence of such...So please quit trying to find a deeper meaning to it. If one really wants to understand everything in this movie, go drop some LSD and sit back and relax, then it might actually make sense.<br /><br />It reminded me of the time I watched Gus Van Sant's Last Days, another movie I was mad about watching. I cannot help but wonder what the ratings would be for that movie, if the same people reviewed it who reviewed this one. It seems like, if the movie's director is totally off his rocker, or if it's a french movie with sex and subtitles, or if it's a cartoon, it is going to get great reviews, hands down, anything else is boring and has already been done. BLAH, bring on the boring please!\n",
      "\n",
      "Labeled Sentiment: negative\n",
      "\n",
      "     SENTIMENT STATS:                                         \n",
      "  Predicted Sentiment Polarity Score Positive Negative Neutral\n",
      "0            positive           0.95     9.0%     5.0%   85.0%\n",
      "------------------------------------------------------------\n",
      "Review:\n",
      "Whoever thought that ANOTHER Home Alone film would be a good idea should have their head examined... Same plot, different kid, more villains (which leads to MORE endless stupidity in the traps). The other two films were bad enough, and this is where it hits rock bottom. People may as well watch the other films for plot, as it's all identical.\n",
      "\n",
      "Labeled Sentiment: negative\n",
      "\n",
      "     SENTIMENT STATS:                                         \n",
      "  Predicted Sentiment Polarity Score Positive Negative Neutral\n",
      "0            negative          -0.88     7.0%    19.0%   74.0%\n",
      "------------------------------------------------------------\n",
      "Review:\n",
      "Great movie. Good acting ,a wonderful script. It's exciting to find out what the people are thinking and how they react on the situation they are in. A pity about the ending; a 'page' of text of how Nynke's life went on, instead of moving images was a poor choice. I hope this movie attracts a lot of people; it's worth it!\n",
      "\n",
      "Labeled Sentiment: positive\n",
      "\n",
      "     SENTIMENT STATS:                                         \n",
      "  Predicted Sentiment Polarity Score Positive Negative Neutral\n",
      "0            positive           0.95    29.0%     7.0%   64.0%\n",
      "------------------------------------------------------------\n",
      "Review:\n",
      "i wish i could find some good things to say about this animated sequel(but not really a sequel)to \"Atlantis:The Lost Empire\"but this would be a very short comment.the magic that the first one had is nowhere to be found here.the animation is pretty poor all over,the characters themselves are not very well drawn.the backgrounds and the foregrounds are also not good.there's very little attention to detail here.and instead of a compelling and engaging story,we have 3 short stories which are boring and don't make a lot of sense.i swear,even the characters sounded like they were bored,and would rather be somewhere else.which says that the voice actors were bored and wanted to be someplace else,at least that's the impression.some of the same actors return for this dismal effort,but an integral par of the success of the first one was Michael J.Fox as the main hero, Milo Thatch.i get the distinct impression this movie was just thrown together to capitalize on the success of the first one,without much thought or care.but at least Cree Summer returns as the voice of \"Kida\".that's probably the only good thing about this movie,and even she doesn't seem to have her heart completely in it.mind you,i guess you couldn't blame any of the cast for not giving their all,considering what they had to work with.or rather not work with.this is a straight to video movie(and i use the term loosely)which should have went straight to the nearest landfill.anyway,shame on Disney.consumers deserve much better than this.this one gets a 0/10 and a well deserved one at that.p.u\n",
      "\n",
      "Labeled Sentiment: negative\n",
      "\n",
      "     SENTIMENT STATS:                                         \n",
      "  Predicted Sentiment Polarity Score Positive Negative Neutral\n",
      "0            positive           0.95    14.0%     7.0%   79.0%\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for review, review_sentiment in sample_data:\n",
    "    print 'Review:'\n",
    "    print review\n",
    "    print\n",
    "    print 'Labeled Sentiment:', review_sentiment    \n",
    "    print    \n",
    "    final_sentiment = analyze_sentiment_vader_lexicon(review, threshold=0.1, verbose=True)\n",
    "    print '-'*60                                                       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance metrics:\n",
      "Accuracy: 0.7\n",
      "Precision: 0.65\n",
      "Recall: 0.85\n",
      "F1 Score: 0.74\n"
     ]
    }
   ],
   "source": [
    "vader_predictions = [analyze_sentiment_vader_lexicon(review, threshold=0.1)\n",
    "                     for review in test_reviews] \n",
    "\n",
    "print 'Performance metrics:'\n",
    "display_evaluation_metrics(true_labels=test_sentiments,\n",
    "                           predicted_labels=vader_predictions,\n",
    "                           positive_class='positive')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "                 Predicted:         \n",
      "                   positive negative\n",
      "Actual: positive       6450     1108\n",
      "        negative       3425     4017\n"
     ]
    }
   ],
   "source": [
    "print '\\nConfusion Matrix:'                           \n",
    "display_confusion_matrix(true_labels=test_sentiments,\n",
    "                         predicted_labels=vader_predictions,\n",
    "                         classes=['positive', 'negative'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive       0.65      0.85      0.74      7558\n",
      "   negative       0.78      0.54      0.64      7442\n",
      "\n",
      "avg / total       0.72      0.70      0.69     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print '\\nClassification report:'                         \n",
    "display_classification_report(true_labels=test_sentiments,\n",
    "                              predicted_labels=vader_predictions,\n",
    "                              classes=['positive', 'negative']) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pattern Lexicon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pattern.en import sentiment, mood, modality\n",
    "\n",
    "def analyze_sentiment_pattern_lexicon(review, threshold=0.1,\n",
    "                                      verbose=False):\n",
    "    # pre-process text\n",
    "    review = normalize_accented_characters(review)\n",
    "    review = html_parser.unescape(review)\n",
    "    review = strip_html(review)\n",
    "    # analyze sentiment for the text document\n",
    "    analysis = sentiment(review)\n",
    "    sentiment_score = round(analysis[0], 2)\n",
    "    sentiment_subjectivity = round(analysis[1], 2)\n",
    "    # get final sentiment\n",
    "    final_sentiment = 'positive' if sentiment_score >= threshold\\\n",
    "                                   else 'negative'\n",
    "    if verbose:\n",
    "        # display detailed sentiment statistics\n",
    "        sentiment_frame = pd.DataFrame([[final_sentiment, sentiment_score,\n",
    "                                        sentiment_subjectivity]],\n",
    "                                        columns=pd.MultiIndex(levels=[['SENTIMENT STATS:'], \n",
    "                                                                      ['Predicted Sentiment', 'Polarity Score',\n",
    "                                                                       'Subjectivity Score']], \n",
    "                                                              labels=[[0,0,0],[0,1,2]]))\n",
    "        print sentiment_frame\n",
    "        assessment = analysis.assessments\n",
    "        assessment_frame = pd.DataFrame(assessment, \n",
    "                                        columns=pd.MultiIndex(levels=[['DETAILED ASSESSMENT STATS:'], \n",
    "                                                                      ['Key Terms', 'Polarity Score',\n",
    "                                                                       'Subjectivity Score', 'Type']], \n",
    "                                                              labels=[[0,0,0,0],[0,1,2,3]]))\n",
    "        print assessment_frame\n",
    "        print\n",
    "    \n",
    "    return final_sentiment                                       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review:\n",
      "Got into this flick, just as it was beginning, on an afternoon where I was home with a touch of flu - otherwise I'd have missed it. That probably would have been best.<br /><br />I noticed the presence of Lindsay Crouse and Jay Thomas - both very good performers - and thought this might be worth a look. It proved to be to some extent, but only because it is one of those stories so awful it fascinates.<br /><br />Zoe McLellan has little to recommend her talents, except for her Jayne Mansfield- or Loni Anderson-like bosom. Unfortunately, her acting prowess - at least here - makes Mansfield and Anderson seem to be Garbo or Davis by comparison.<br /><br />The young nut case's white rat, the owner's cat, the young nut case having the owner evicted and restrained in her own home, and a bunch of doophus's (including the young nut case) running around a bio hazard facility, and the absurd conclusion. I kept waiting for at least some scene or plot element to contain at least a modicum of realism, believability or being capable of evoking some empathy/sympathy -- but this proved to be in vain.\n",
      "\n",
      "Labeled Sentiment: negative\n",
      "\n",
      "     SENTIMENT STATS:                                  \n",
      "  Predicted Sentiment Polarity Score Subjectivity Score\n",
      "0            negative           0.01               0.53\n",
      "   DETAILED ASSESSMENT STATS:                                        \n",
      "                    Key Terms Polarity Score Subjectivity Score  Type\n",
      "0                      [best]         1.0000               0.30  None\n",
      "1                [very, good]         0.9100               0.78  None\n",
      "2                     [worth]         0.3000               0.10  None\n",
      "3                      [only]         0.0000               1.00  None\n",
      "4                     [awful]        -1.0000               1.00  None\n",
      "5                    [little]        -0.1875               0.50  None\n",
      "6             [unfortunately]        -0.5000               1.00  None\n",
      "7                    [acting]         0.0000               0.00  None\n",
      "8                     [least]        -0.3000               0.40  None\n",
      "9                     [young]         0.1000               0.40  None\n",
      "10                    [white]         0.0000               0.00  None\n",
      "11                    [young]         0.1000               0.40  None\n",
      "12                      [own]         0.6000               1.00  None\n",
      "13                    [young]         0.1000               0.40  None\n",
      "14                   [absurd]        -0.5000               1.00  None\n",
      "15                    [least]        -0.3000               0.40  None\n",
      "16                    [least]        -0.3000               0.40  None\n",
      "17                  [capable]         0.2000               0.40  None\n",
      "\n",
      "------------------------------------------------------------\n",
      "Review:\n",
      "I think this movie is amazing but there is one problem. there is one song that i want to find but cannot find it. it starts on about 18 minutes just after the coach has said \"what are u the runt of the family\", and then looks at the fat kid takes his hat off then he says go, the song that starts there, i would like to know what it is? Does any 1 no email me please or add a comment.It Starts Zaga Zow, Ziga Zow something along those lines. I just think it is an amazing dance track i would love to have that song so that i could use it in my break dancing lessons. It starts when they are jumping and running over the orange fast stepper things which are used in football training to help you run faster\n",
      "\n",
      "Labeled Sentiment: positive\n",
      "\n",
      "     SENTIMENT STATS:                                  \n",
      "  Predicted Sentiment Polarity Score Subjectivity Score\n",
      "0            positive           0.48               0.75\n",
      "  DETAILED ASSESSMENT STATS:                                        \n",
      "                   Key Terms Polarity Score Subjectivity Score  Type\n",
      "0                  [amazing]            0.6                0.9  None\n",
      "1                  [amazing]            0.6                0.9  None\n",
      "2                     [love]            0.5                0.6  None\n",
      "3                     [fast]            0.2                0.6  None\n",
      "\n",
      "------------------------------------------------------------\n",
      "Review:\n",
      "I recently picked up all three Robocop films in one box set, rather cheaply and the only reason I did this was for the special edition of the superb first one. I have seen Robocop 2 before but not for 17 years, the year it came out. I have never watched it since because I can still remember how disappointed I was when I discovered how appalling it really is. Its a complete mess really, it has all the signs of a troubled production with so many sub-plots going on at the same time. It has a very uneven tone also and it is also one of the nastiest films I have ever seen. I don't mind a little violence, the first one was incredibly violent but this one is just plain nasty. Also the SFX is terrible even for 1990, say hello to bad stop motion. Also having a drug dealing, cursing kid as a villain is just a little too much. Peter Weller at least had the common sense not to return for the next one. The only positive thing I can say for this film is it does have a couple of nice gags, like the thank you for not smoking one and the kiddie baseball team robbing an electrics store. To quote the kid who plays the villain \"It sucks\"\n",
      "\n",
      "Labeled Sentiment: negative\n",
      "\n",
      "     SENTIMENT STATS:                                  \n",
      "  Predicted Sentiment Polarity Score Subjectivity Score\n",
      "0            negative          -0.09               0.55\n",
      "   DETAILED ASSESSMENT STATS:                                             \n",
      "                    Key Terms Polarity Score Subjectivity Score       Type\n",
      "0                  [recently]       0.000000           0.250000       None\n",
      "1                   [cheaply]       0.400000           0.700000       None\n",
      "2                      [only]       0.000000           1.000000       None\n",
      "3                   [special]       0.357143           0.571429       None\n",
      "4                    [superb]       1.000000           1.000000       None\n",
      "5                     [first]       0.250000           0.333333       None\n",
      "6              [disappointed]      -0.750000           0.750000       None\n",
      "7                 [appalling]      -0.350000           0.900000       None\n",
      "8                    [really]       0.200000           0.200000       None\n",
      "9                  [complete]       0.100000           0.400000       None\n",
      "10                     [mess]      -0.175000           0.175000       None\n",
      "11                   [really]       0.200000           0.200000       None\n",
      "12                 [troubled]      -0.500000           1.000000       None\n",
      "13                     [many]       0.500000           0.500000       None\n",
      "14                     [same]       0.000000           0.125000       None\n",
      "15             [very, uneven]      -0.260000           0.260000       None\n",
      "16                   [little]      -0.187500           0.500000       None\n",
      "17                    [first]       0.250000           0.333333       None\n",
      "18      [incredibly, violent]      -0.800000           1.000000       None\n",
      "19                    [plain]      -0.214286           0.357143       None\n",
      "20                    [nasty]      -1.000000           1.000000       None\n",
      "21                 [terrible]      -1.000000           1.000000       None\n",
      "22                      [bad]      -0.700000           0.666667       None\n",
      "23                   [little]      -0.187500           0.500000       None\n",
      "24                     [much]       0.200000           0.200000       None\n",
      "25                    [least]      -0.300000           0.400000       None\n",
      "26                   [common]      -0.300000           0.500000       None\n",
      "27                     [next]       0.000000           0.000000       None\n",
      "28                     [only]       0.000000           1.000000       None\n",
      "29                 [positive]       0.227273           0.545455       None\n",
      "30                     [nice]       0.600000           1.000000       None\n",
      "31                    [sucks]      -0.300000           0.300000  profanity\n",
      "\n",
      "------------------------------------------------------------\n",
      "Review:\n",
      "This is a little film with a big heart. Excellent acting throughout and directed with love. If you missed it in theatres (and who didn't?), catch it with someone you love. Frankly, I cried! And I'm a guy, for cryin' out loud!\n",
      "\n",
      "Labeled Sentiment: positive\n",
      "\n",
      "     SENTIMENT STATS:                                  \n",
      "  Predicted Sentiment Polarity Score Subjectivity Score\n",
      "0            positive           0.29               0.51\n",
      "  DETAILED ASSESSMENT STATS:                                        \n",
      "                   Key Terms Polarity Score Subjectivity Score  Type\n",
      "0                   [little]        -0.1875                0.5  None\n",
      "1                      [big]         0.0000                0.1  None\n",
      "2                [excellent]         1.0000                1.0  None\n",
      "3                   [acting]         0.0000                0.0  None\n",
      "4                     [love]         0.5000                0.6  None\n",
      "5                  [love, !]         0.6250                0.6  None\n",
      "6                  [loud, !]         0.1250                0.8  None\n",
      "\n",
      "------------------------------------------------------------\n",
      "Review:\n",
      "I watched this movie and all I can say is this...I am not a film student, nor am I some artsy intellect who tries to look for a deeper meaning into everything that I don't understand. However, IF I were to do that with this film, my thoughts would be...<br /><br />Yep! He's on drugs and I can picture it now...he was tripping one night and sat around with his buddies laughing and saying stuff like, hey...wouldn't it be funny if nuns really could fly? Like what if one just fell out of a plane and free fell for a while, bounced to the ground and got up and walked away? *cackles* or if buckwheat gave the pope a bath? oh my god, I'm cracking up just thinking about it! Dude! We gotta make a movie about it! And then he says to his friend as he's laughing...Oh and wouldn't it be hilarious if people loved it and called me a genius for it? So to me, this is what happens when some guy does one too many drugs and writes a script and produces a movie. Should I have been doing LSD to understand what this guy was thinking so I could have had a laugh too? Because I have to tell you, I wasn't laughing. I was yawning and checking the time.<br /><br />I think everyone who is trying their hardest to find a deeper meaning is hysterical. I had never heard of this director until I came to read the reviews, which I did because I was mad that I lost that last 2 hrs, or how ever long it was, (it felt like 12 hrs of my life) and I can't ever get it back, anyway...I have read that this guy is a heroine addict and he wanted to die for art?? what the heck is that? So my point is sort of proved. This guy is not all there, he's a drug addict, and his movie is evidence of such...So please quit trying to find a deeper meaning to it. If one really wants to understand everything in this movie, go drop some LSD and sit back and relax, then it might actually make sense.<br /><br />It reminded me of the time I watched Gus Van Sant's Last Days, another movie I was mad about watching. I cannot help but wonder what the ratings would be for that movie, if the same people reviewed it who reviewed this one. It seems like, if the movie's director is totally off his rocker, or if it's a french movie with sex and subtitles, or if it's a cartoon, it is going to get great reviews, hands down, anything else is boring and has already been done. BLAH, bring on the boring please!\n",
      "\n",
      "Labeled Sentiment: negative\n",
      "\n",
      "     SENTIMENT STATS:                                  \n",
      "  Predicted Sentiment Polarity Score Subjectivity Score\n",
      "0            negative           0.02               0.51\n",
      "   DETAILED ASSESSMENT STATS:                                        \n",
      "                    Key Terms Polarity Score Subjectivity Score  Type\n",
      "0                  [tries, !]      -0.125000           0.400000  None\n",
      "1                     [funny]       0.250000           1.000000  None\n",
      "2                    [really]       0.200000           0.200000  None\n",
      "3                       [fly]       0.800000           0.900000  None\n",
      "4             [free, !, !, !]       0.781250           0.800000  None\n",
      "5                 [hilarious]       0.500000           1.000000  None\n",
      "6                     [loved]       0.700000           0.800000  None\n",
      "7                      [many]       0.500000           0.500000  None\n",
      "8                     [laugh]       0.300000           0.100000  None\n",
      "9                [hysterical]      -1.000000           1.000000  None\n",
      "10                      [mad]      -0.625000           1.000000  None\n",
      "11                     [last]       0.000000           0.066667  None\n",
      "12                     [long]      -0.050000           0.400000  None\n",
      "13                     [back]       0.000000           0.000000  None\n",
      "14            [really, wants]       0.200000           0.100000  None\n",
      "15                     [back]       0.000000           0.000000  None\n",
      "16                 [actually]       0.000000           0.100000  None\n",
      "17                     [last]       0.000000           0.066667  None\n",
      "18                      [mad]      -0.625000           1.000000  None\n",
      "19                     [same]       0.000000           0.125000  None\n",
      "20                  [totally]       0.000000           0.750000  None\n",
      "21                   [french]       0.000000           0.000000  None\n",
      "22                    [great]       0.800000           0.750000  None\n",
      "23                     [down]      -0.155556           0.288889  None\n",
      "24                   [boring]      -1.000000           1.000000  None\n",
      "25                [boring, !]      -1.000000           1.000000  None\n",
      "\n",
      "------------------------------------------------------------\n",
      "Review:\n",
      "Whoever thought that ANOTHER Home Alone film would be a good idea should have their head examined... Same plot, different kid, more villains (which leads to MORE endless stupidity in the traps). The other two films were bad enough, and this is where it hits rock bottom. People may as well watch the other films for plot, as it's all identical.\n",
      "\n",
      "Labeled Sentiment: negative\n",
      "\n",
      "     SENTIMENT STATS:                                  \n",
      "  Predicted Sentiment Polarity Score Subjectivity Score\n",
      "0            negative           0.06                0.5\n",
      "  DETAILED ASSESSMENT STATS:                                        \n",
      "                   Key Terms Polarity Score Subjectivity Score  Type\n",
      "0                     [good]          0.700           0.600000  None\n",
      "1                     [same]          0.000           0.125000  None\n",
      "2                [different]          0.000           0.600000  None\n",
      "3                     [more]          0.500           0.500000  None\n",
      "4                     [more]          0.500           0.500000  None\n",
      "5                  [endless]         -0.125           0.750000  None\n",
      "6                    [other]         -0.125           0.375000  None\n",
      "7                      [bad]         -0.700           0.666667  None\n",
      "8                   [enough]          0.000           0.500000  None\n",
      "9                    [other]         -0.125           0.375000  None\n",
      "\n",
      "------------------------------------------------------------\n",
      "Review:\n",
      "Great movie. Good acting ,a wonderful script. It's exciting to find out what the people are thinking and how they react on the situation they are in. A pity about the ending; a 'page' of text of how Nynke's life went on, instead of moving images was a poor choice. I hope this movie attracts a lot of people; it's worth it!\n",
      "\n",
      "Labeled Sentiment: positive\n",
      "\n",
      "     SENTIMENT STATS:                                  \n",
      "  Predicted Sentiment Polarity Score Subjectivity Score\n",
      "0            positive           0.33               0.51\n",
      "  DETAILED ASSESSMENT STATS:                                        \n",
      "                   Key Terms Polarity Score Subjectivity Score  Type\n",
      "0                    [great]          0.800               0.75  None\n",
      "1                     [good]          0.700               0.60  None\n",
      "2                   [acting]          0.000               0.00  None\n",
      "3                [wonderful]          1.000               1.00  None\n",
      "4                 [exciting]          0.300               0.80  None\n",
      "5                     [pity]         -0.100               0.20  None\n",
      "6                     [poor]         -0.400               0.60  None\n",
      "7                 [worth, !]          0.375               0.10  None\n",
      "\n",
      "------------------------------------------------------------\n",
      "Review:\n",
      "i wish i could find some good things to say about this animated sequel(but not really a sequel)to \"Atlantis:The Lost Empire\"but this would be a very short comment.the magic that the first one had is nowhere to be found here.the animation is pretty poor all over,the characters themselves are not very well drawn.the backgrounds and the foregrounds are also not good.there's very little attention to detail here.and instead of a compelling and engaging story,we have 3 short stories which are boring and don't make a lot of sense.i swear,even the characters sounded like they were bored,and would rather be somewhere else.which says that the voice actors were bored and wanted to be someplace else,at least that's the impression.some of the same actors return for this dismal effort,but an integral par of the success of the first one was Michael J.Fox as the main hero, Milo Thatch.i get the distinct impression this movie was just thrown together to capitalize on the success of the first one,without much thought or care.but at least Cree Summer returns as the voice of \"Kida\".that's probably the only good thing about this movie,and even she doesn't seem to have her heart completely in it.mind you,i guess you couldn't blame any of the cast for not giving their all,considering what they had to work with.or rather not work with.this is a straight to video movie(and i use the term loosely)which should have went straight to the nearest landfill.anyway,shame on Disney.consumers deserve much better than this.this one gets a 0/10 and a well deserved one at that.p.u\n",
      "\n",
      "Labeled Sentiment: negative\n",
      "\n",
      "     SENTIMENT STATS:                                  \n",
      "  Predicted Sentiment Polarity Score Subjectivity Score\n",
      "0            positive            0.1               0.48\n",
      "   DETAILED ASSESSMENT STATS:                                        \n",
      "                    Key Terms Polarity Score Subjectivity Score  Type\n",
      "0                      [good]       0.700000           0.600000  None\n",
      "1               [not, really]      -0.100000           0.200000  None\n",
      "2               [very, short]       0.000000           0.390000  None\n",
      "3                     [magic]       0.500000           1.000000  None\n",
      "4                     [first]       0.250000           0.333333  None\n",
      "5                    [pretty]       0.250000           1.000000  None\n",
      "6                      [poor]      -0.400000           0.600000  None\n",
      "7                 [not, very]      -0.100000           0.300000  None\n",
      "8              [very, little]      -0.243750           0.650000  None\n",
      "9                [compelling]       0.300000           0.600000  None\n",
      "10                 [engaging]       0.400000           0.700000  None\n",
      "11                    [short]       0.000000           0.300000  None\n",
      "12                   [boring]      -1.000000           1.000000  None\n",
      "13                    [bored]      -0.500000           1.000000  None\n",
      "14                    [least]      -0.300000           0.400000  None\n",
      "15                     [same]       0.000000           0.125000  None\n",
      "16                  [success]       0.300000           0.000000  None\n",
      "17                    [first]       0.250000           0.333333  None\n",
      "18                     [main]       0.166667           0.333333  None\n",
      "19                 [distinct]       0.300000           0.300000  None\n",
      "20                  [success]       0.300000           0.000000  None\n",
      "21                    [first]       0.250000           0.333333  None\n",
      "22                     [much]       0.200000           0.200000  None\n",
      "23                    [least]      -0.300000           0.400000  None\n",
      "24                     [only]       0.000000           1.000000  None\n",
      "25                     [good]       0.700000           0.600000  None\n",
      "26               [completely]       0.100000           0.400000  None\n",
      "27                 [straight]       0.200000           0.400000  None\n",
      "28                 [straight]       0.200000           0.400000  None\n",
      "29             [much, better]       0.500000           0.500000  None\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for review, review_sentiment in sample_data:\n",
    "    print 'Review:'\n",
    "    print review\n",
    "    print\n",
    "    print 'Labeled Sentiment:', review_sentiment    \n",
    "    print    \n",
    "    final_sentiment = analyze_sentiment_pattern_lexicon(review,\n",
    "                                                        threshold=0.1,\n",
    "                                                        verbose=True)\n",
    "    print '-'*60            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review:\n",
      "Got into this flick, just as it was beginning, on an afternoon where I was home with a touch of flu - otherwise I'd have missed it. That probably would have been best.<br /><br />I noticed the presence of Lindsay Crouse and Jay Thomas - both very good performers - and thought this might be worth a look. It proved to be to some extent, but only because it is one of those stories so awful it fascinates.<br /><br />Zoe McLellan has little to recommend her talents, except for her Jayne Mansfield- or Loni Anderson-like bosom. Unfortunately, her acting prowess - at least here - makes Mansfield and Anderson seem to be Garbo or Davis by comparison.<br /><br />The young nut case's white rat, the owner's cat, the young nut case having the owner evicted and restrained in her own home, and a bunch of doophus's (including the young nut case) running around a bio hazard facility, and the absurd conclusion. I kept waiting for at least some scene or plot element to contain at least a modicum of realism, believability or being capable of evoking some empathy/sympathy -- but this proved to be in vain.\n",
      "Labeled Sentiment: negative\n",
      "Mood: conditional\n",
      "Modality Score: 0.19\n",
      "Certainty: Low\n",
      "------------------------------------------------------------\n",
      "Review:\n",
      "I think this movie is amazing but there is one problem. there is one song that i want to find but cannot find it. it starts on about 18 minutes just after the coach has said \"what are u the runt of the family\", and then looks at the fat kid takes his hat off then he says go, the song that starts there, i would like to know what it is? Does any 1 no email me please or add a comment.It Starts Zaga Zow, Ziga Zow something along those lines. I just think it is an amazing dance track i would love to have that song so that i could use it in my break dancing lessons. It starts when they are jumping and running over the orange fast stepper things which are used in football training to help you run faster\n",
      "Labeled Sentiment: positive\n",
      "Mood: conditional\n",
      "Modality Score: 0.14\n",
      "Certainty: Low\n",
      "------------------------------------------------------------\n",
      "Review:\n",
      "I recently picked up all three Robocop films in one box set, rather cheaply and the only reason I did this was for the special edition of the superb first one. I have seen Robocop 2 before but not for 17 years, the year it came out. I have never watched it since because I can still remember how disappointed I was when I discovered how appalling it really is. Its a complete mess really, it has all the signs of a troubled production with so many sub-plots going on at the same time. It has a very uneven tone also and it is also one of the nastiest films I have ever seen. I don't mind a little violence, the first one was incredibly violent but this one is just plain nasty. Also the SFX is terrible even for 1990, say hello to bad stop motion. Also having a drug dealing, cursing kid as a villain is just a little too much. Peter Weller at least had the common sense not to return for the next one. The only positive thing I can say for this film is it does have a couple of nice gags, like the thank you for not smoking one and the kiddie baseball team robbing an electrics store. To quote the kid who plays the villain \"It sucks\"\n",
      "Labeled Sentiment: negative\n",
      "Mood: conditional\n",
      "Modality Score: 0.36\n",
      "Certainty: Medium\n",
      "------------------------------------------------------------\n",
      "Review:\n",
      "This is a little film with a big heart. Excellent acting throughout and directed with love. If you missed it in theatres (and who didn't?), catch it with someone you love. Frankly, I cried! And I'm a guy, for cryin' out loud!\n",
      "Labeled Sentiment: positive\n",
      "Mood: indicative\n",
      "Modality Score: 0.75\n",
      "Certainty: Strong\n",
      "------------------------------------------------------------\n",
      "Review:\n",
      "I watched this movie and all I can say is this...I am not a film student, nor am I some artsy intellect who tries to look for a deeper meaning into everything that I don't understand. However, IF I were to do that with this film, my thoughts would be...<br /><br />Yep! He's on drugs and I can picture it now...he was tripping one night and sat around with his buddies laughing and saying stuff like, hey...wouldn't it be funny if nuns really could fly? Like what if one just fell out of a plane and free fell for a while, bounced to the ground and got up and walked away? *cackles* or if buckwheat gave the pope a bath? oh my god, I'm cracking up just thinking about it! Dude! We gotta make a movie about it! And then he says to his friend as he's laughing...Oh and wouldn't it be hilarious if people loved it and called me a genius for it? So to me, this is what happens when some guy does one too many drugs and writes a script and produces a movie. Should I have been doing LSD to understand what this guy was thinking so I could have had a laugh too? Because I have to tell you, I wasn't laughing. I was yawning and checking the time.<br /><br />I think everyone who is trying their hardest to find a deeper meaning is hysterical. I had never heard of this director until I came to read the reviews, which I did because I was mad that I lost that last 2 hrs, or how ever long it was, (it felt like 12 hrs of my life) and I can't ever get it back, anyway...I have read that this guy is a heroine addict and he wanted to die for art?? what the heck is that? So my point is sort of proved. This guy is not all there, he's a drug addict, and his movie is evidence of such...So please quit trying to find a deeper meaning to it. If one really wants to understand everything in this movie, go drop some LSD and sit back and relax, then it might actually make sense.<br /><br />It reminded me of the time I watched Gus Van Sant's Last Days, another movie I was mad about watching. I cannot help but wonder what the ratings would be for that movie, if the same people reviewed it who reviewed this one. It seems like, if the movie's director is totally off his rocker, or if it's a french movie with sex and subtitles, or if it's a cartoon, it is going to get great reviews, hands down, anything else is boring and has already been done. BLAH, bring on the boring please!\n",
      "Labeled Sentiment: negative\n",
      "Mood: subjunctive\n",
      "Modality Score: 0.09\n",
      "Certainty: Low\n",
      "------------------------------------------------------------\n",
      "Review:\n",
      "Whoever thought that ANOTHER Home Alone film would be a good idea should have their head examined... Same plot, different kid, more villains (which leads to MORE endless stupidity in the traps). The other two films were bad enough, and this is where it hits rock bottom. People may as well watch the other films for plot, as it's all identical.\n",
      "Labeled Sentiment: negative\n",
      "Mood: conditional\n",
      "Modality Score: 0.13\n",
      "Certainty: Low\n",
      "------------------------------------------------------------\n",
      "Review:\n",
      "Great movie. Good acting ,a wonderful script. It's exciting to find out what the people are thinking and how they react on the situation they are in. A pity about the ending; a 'page' of text of how Nynke's life went on, instead of moving images was a poor choice. I hope this movie attracts a lot of people; it's worth it!\n",
      "Labeled Sentiment: positive\n",
      "Mood: indicative\n",
      "Modality Score: 0.33\n",
      "Certainty: Low\n",
      "------------------------------------------------------------\n",
      "Review:\n",
      "i wish i could find some good things to say about this animated sequel(but not really a sequel)to \"Atlantis:The Lost Empire\"but this would be a very short comment.the magic that the first one had is nowhere to be found here.the animation is pretty poor all over,the characters themselves are not very well drawn.the backgrounds and the foregrounds are also not good.there's very little attention to detail here.and instead of a compelling and engaging story,we have 3 short stories which are boring and don't make a lot of sense.i swear,even the characters sounded like they were bored,and would rather be somewhere else.which says that the voice actors were bored and wanted to be someplace else,at least that's the impression.some of the same actors return for this dismal effort,but an integral par of the success of the first one was Michael J.Fox as the main hero, Milo Thatch.i get the distinct impression this movie was just thrown together to capitalize on the success of the first one,without much thought or care.but at least Cree Summer returns as the voice of \"Kida\".that's probably the only good thing about this movie,and even she doesn't seem to have her heart completely in it.mind you,i guess you couldn't blame any of the cast for not giving their all,considering what they had to work with.or rather not work with.this is a straight to video movie(and i use the term loosely)which should have went straight to the nearest landfill.anyway,shame on Disney.consumers deserve much better than this.this one gets a 0/10 and a well deserved one at that.p.u\n",
      "Labeled Sentiment: negative\n",
      "Mood: conditional\n",
      "Modality Score: 0.05\n",
      "Certainty: Low\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for review, review_sentiment in sample_data:\n",
    "    print 'Review:'\n",
    "    print review\n",
    "    print 'Labeled Sentiment:', review_sentiment \n",
    "    print 'Mood:', mood(review)\n",
    "    mod_score = modality(review)\n",
    "    print 'Modality Score:', round(mod_score, 2)\n",
    "    print 'Certainty:', 'Strong' if mod_score > 0.5 \\\n",
    "                                    else 'Medium' if mod_score > 0.35 \\\n",
    "                                                    else 'Low'\n",
    "    print '-'*60            \n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python2]",
   "language": "python",
   "name": "conda-env-python2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
